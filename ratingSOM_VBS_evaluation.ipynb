{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "#import ratingSOM\n",
    "#from ratingSOM import SOM\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to implement simple self organizing map using PyTorch, with methods\n",
    "similar to clustering method in sklearn.\n",
    "@author: Riley Smith\n",
    "Created: 1-27-21\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class SOM():\n",
    "    \"\"\"\n",
    "    The 2-D, rectangular grid self-organizing map class using Numpy.\n",
    "    \"\"\"\n",
    "    def __init__(self, m=3, n=3, dim=3, lr=1, sigma=1, max_iter=3000,\n",
    "                    random_state=None, som_type=\"normal\", alpha=0.5, use_triangular=False, use_prob_candidate_selection = False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        m : int, default=3\n",
    "            The shape along dimension 0 (vertical) of the SOM.\n",
    "        n : int, default=3\n",
    "            The shape along dimesnion 1 (horizontal) of the SOM.\n",
    "        dim : int, default=3\n",
    "            The dimensionality (number of features) of the input space.\n",
    "        lr : float, default=1\n",
    "            The initial step size for updating the SOM weights.\n",
    "        sigma : float, optional\n",
    "            Optional parameter for magnitude of change to each weight. Does not\n",
    "            update over training (as does learning rate). Higher values mean\n",
    "            more aggressive updates to weights.\n",
    "        max_iter : int, optional\n",
    "            Optional parameter to stop training if you reach this many\n",
    "            interation.\n",
    "        random_state : int, optional\n",
    "            Optional integer seed to the random number generator for weight\n",
    "            initialization. This will be used to create a new instance of Numpy's\n",
    "            default random number generator (it will not call np.random.seed()).\n",
    "            Specify an integer for deterministic results.\n",
    "        som_type : string, optional\n",
    "            Options to determine whether classical (normal), rating-aware (rating), rank-aware (rank), or rank aware\n",
    "            with positional discounts (rank_pos) SOM is performed\n",
    "        alpha: float, optional\n",
    "            Hyperparameter to tune importance of ranking vs. local similarity. \n",
    "            Higher alpha values denote more importance to the local similarity (original SOM)\n",
    "        use_triangular: bool, optional\n",
    "            Determine the ranking of displayed grid coordinates: row-first bases (False) \n",
    "            or triangular starting from top-left corner (True)    \n",
    "        use_prob_candidate_selection: bool, optional\n",
    "            For each epoch, candidates are either selected uniformly (False) or based on probability distribution (True)\n",
    "            Probability distribution is supposed to be induced by the rating of individual candidates\n",
    "            (better rating => higher probability to affect SOM composition)\n",
    "        \"\"\"\n",
    "        # Initialize descriptive features of SOM\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.shape = (m, n)\n",
    "        self.initial_lr = lr\n",
    "        self.lr = lr\n",
    "        self.sigma = sigma\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        \n",
    "        #initialize rankingSOM specific features\n",
    "        self.som_type = som_type\n",
    "        self.alpha = alpha\n",
    "        self.use_triangular = use_triangular\n",
    "        self.use_prob_candidate_selection = use_prob_candidate_selection\n",
    "        self.triangular_ordering = self._get_golden_triangle_ordering(m).reshape(-1)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.random_state = random_state\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        self.weights = rng.normal(size=(m * n, dim))\n",
    "        self._locations = self._get_locations(m, n)\n",
    "\n",
    "        # Set after fitting\n",
    "        self._inertia = None\n",
    "        self._n_iter_ = None\n",
    "        self._trained = False\n",
    "        \n",
    "        \n",
    "    def _get_golden_triangle_ordering(self, size):\n",
    "        #get ordering of the golden triangle starting from top-left corner and going over second diagonal.\n",
    "        #having a 3x3 square, the ordering is [0,0], [0,1], [1,0], [0,2], [1,1], [2,0], [1,2], [2,1], [2,2]\n",
    "        #only works for squares (extension for rectangles plausible TODO)\n",
    "        maxIndexSum = size*2 -1\n",
    "        listOfIndices = []\n",
    "\n",
    "        for n in range(maxIndexSum):\n",
    "            for i in range(size):\n",
    "                firstIndex = i\n",
    "                secondIndex = n-i\n",
    "                if secondIndex < size and secondIndex >= 0:\n",
    "                    listOfIndices.append((firstIndex,secondIndex))\n",
    "\n",
    "\n",
    "        mat = np.zeros((size,size),dtype=int)   \n",
    "        vals = np.array(range(size**2))\n",
    "\n",
    "        for i,idx in enumerate(listOfIndices):\n",
    "            mat[idx] = vals[i]\n",
    "        return mat\n",
    "\n",
    "\n",
    "    def _get_locations(self, m, n):\n",
    "        \"\"\"\n",
    "        Return the indices of an m by n array.\n",
    "        \"\"\"\n",
    "        return np.argwhere(np.ones(shape=(m, n))).astype(np.int64)\n",
    "\n",
    "    def _find_bmu(self, x):\n",
    "        \"\"\"\n",
    "        Find the index of the best matching unit for the input vector x.\n",
    "        \"\"\"\n",
    "        # Stack x to have one row per weight\n",
    "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
    "        # Calculate distance between x and each weight\n",
    "        distance = np.linalg.norm(x_stack - self.weights, axis=1)\n",
    "        # Find index of best matching unit\n",
    "        return np.argmin(distance)\n",
    "\n",
    "    def _find_bmu_rank_aware(self, x, rank, rating):\n",
    "        \"\"\"\n",
    "        Consider ranking of individual cases\n",
    "        Directly optimizing Kendall Tau coefficient\n",
    "        Approximative normalization due to comparability between both distance metrics\n",
    "        Possible problem: too small difference of rank-aware distances if m*n is small compared to total volume of samples\n",
    "        \"\"\"\n",
    "        # Stack x to have one row per weight\n",
    "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
    "        # Calculate distance between x and each weight\n",
    "        distance = np.linalg.norm(x_stack - self.weights, axis=1)\n",
    "        # Find index of best matching unit\n",
    "        \n",
    "        x_rank_stack = np.array([rank+1]*(self.m*self.n))\n",
    "        \n",
    "        # Use row-wise or left-top triangular ordering of grid\n",
    "        if self.use_triangular == True:\n",
    "            nodes_rank = self.triangular_ordering+1\n",
    "        else:            \n",
    "            nodes_rank = np.array(range((self.m*self.n)))+1\n",
    "        \n",
    "        rankDistance = np.absolute(x_rank_stack-nodes_rank) / self.volume_of_samples\n",
    "        \n",
    "        finalDistance = self.alpha * distance + (1-self.alpha) * rankDistance\n",
    "        return np.argmin(finalDistance)\n",
    "    \n",
    "    \n",
    "    def _find_bmu_rank_aware_positional(self, x, rank, rating):\n",
    "        \"\"\"\n",
    "        Consider ranking of individual cases\n",
    "        Rather drastic increase in importance w.r.t. position of item (more important on top positions than later on)\n",
    "        Does not optimize any well-known metric in particular, but may provide visually reasonable results\n",
    "        \"\"\"\n",
    "        # Stack x to have one row per weight\n",
    "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
    "        # Calculate distance between x and each weight\n",
    "        distance = np.linalg.norm(x_stack - self.weights, axis=1)\n",
    "        # Find index of best matching unit\n",
    "        \n",
    "        x_rank_stack = np.array([rank+1]*(self.m*self.n))\n",
    "        \n",
    "        # Use row-wise or left-top triangular ordering of grid\n",
    "        if self.use_triangular == True:\n",
    "            nodes_rank = self.triangular_ordering+1\n",
    "        else:            \n",
    "            nodes_rank = np.array(range((self.m*self.n)))+1\n",
    "        \n",
    "        # the part of denominator self.volume_of_samples/(self.m*self.n) is not necessary\n",
    "        # it is kept to normalize the results to the _find_bmu_rank_aware() function (the last node has the same penalty)\n",
    "        rankDistance = np.absolute(x_rank_stack-nodes_rank) / (nodes_rank * self.volume_of_samples/(self.m*self.n))\n",
    "        \n",
    "        finalDistance = self.alpha * distance + (1-self.alpha) * rankDistance\n",
    "        return np.argmin(finalDistance)\n",
    "    \n",
    "    \n",
    "    def _find_bmu_rating_aware(self, x, rank, rating):\n",
    "        \"\"\"\n",
    "        Consider ratings of individual cases\n",
    "        Optimize piece-wise DCG (i.e., difference between expected relevance on this position and the actual one)\n",
    "        Importance of the distance for particular field is weighted in the same way as in nDCG (1/log2(pos+1))\n",
    "        \"\"\"\n",
    "        \n",
    "        # Stack x to have one row per weight\n",
    "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
    "        # Calculate distance between x and each weight\n",
    "        distance = np.linalg.norm(x_stack - self.weights, axis=1)\n",
    "        # Find index of best matching unit\n",
    "        \n",
    "        x_rating_stack = np.array([rating]*(self.m*self.n))   \n",
    "        \n",
    "        # Use row-wise or left-top triangular ordering of grid\n",
    "        if self.use_triangular == True:\n",
    "            nodes_rank = self.triangular_ordering+1\n",
    "        else:            \n",
    "            nodes_rank = np.array(range((self.m*self.n)))+1\n",
    "            \n",
    "        rankBasedWeights = 1/np.log2(nodes_rank+1)       \n",
    "        rankDistance = rankBasedWeights * np.absolute(x_rating_stack-self.expected_ratings)\n",
    "        \n",
    "        finalDistance = self.alpha * distance + (1-self.alpha) * rankDistance\n",
    "        return np.argmin(finalDistance)\n",
    "        \n",
    "    \n",
    "    def step(self, x, rank, rating):\n",
    "        \"\"\"\n",
    "        Do one step of training on the given input vector.\n",
    "        \"\"\"\n",
    "        # Stack x to have one row per weight\n",
    "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
    "\n",
    "        # Get index of best matching unit\n",
    "        # Based on the SOM type, different procedures are applied here\n",
    "        # - this is the only difference between normal SOM and rank-aware SOM\n",
    "        \n",
    "        #classical (normal), rating-aware (rating), rank-aware (rank), or rank aware with positional discounts (rank_pos)\n",
    "        if self.som_type == \"normal\":\n",
    "            bmu_index = self._find_bmu(x)\n",
    "        elif self.som_type == \"rating\":\n",
    "            bmu_index = self._find_bmu_rating_aware(x, rank, rating)        \n",
    "        elif self.som_type == \"rank\":\n",
    "            bmu_index = self._find_bmu_rank_aware(x, rank, rating)\n",
    "        elif self.som_type == \"rank_pos\":\n",
    "            bmu_index = self._find_bmu_rank_aware_positional(x, rank, rating)            \n",
    "            \n",
    "        # Find location of best matching unit\n",
    "        bmu_location = self._locations[bmu_index,:]\n",
    "\n",
    "        # Find square distance from each weight to the BMU\n",
    "        stacked_bmu = np.stack([bmu_location]*(self.m*self.n), axis=0)\n",
    "        bmu_distance = np.sum(np.power(self._locations.astype(np.float64) - stacked_bmu.astype(np.float64), 2), axis=1)\n",
    "\n",
    "        # Compute update neighborhood\n",
    "        neighborhood = np.exp((bmu_distance / (self.sigma ** 2)) * -1)\n",
    "        local_step = self.lr * neighborhood\n",
    "\n",
    "        # Stack local step to be proper shape for update\n",
    "        local_multiplier = np.stack([local_step]*(self.dim), axis=1)\n",
    "\n",
    "        # Multiply by difference between input and weights\n",
    "        delta = local_multiplier * (x_stack - self.weights)\n",
    "\n",
    "        # Update weights\n",
    "        self.weights += delta\n",
    "\n",
    "    def _compute_point_intertia(self, x):\n",
    "        \"\"\"\n",
    "        Compute the inertia of a single point. Inertia defined as squared distance\n",
    "        from point to closest cluster center (BMU)\n",
    "        \"\"\"\n",
    "        # Find BMU\n",
    "        bmu_index = self._find_bmu(x)\n",
    "        bmu = self.weights[bmu_index]\n",
    "        # Compute sum of squared distance (just euclidean distance) from x to bmu\n",
    "        return np.sum(np.square(x - bmu))\n",
    "\n",
    "    def fit(self, X, ranks, ratings, epochs=1, shuffle=True):\n",
    "        \"\"\"\n",
    "        Take data (a tensor of type float64) as input and fit the SOM to that\n",
    "        data for the specified number of epochs.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Training data. Must have shape (n, self.dim) where n is the number\n",
    "            of training samples.\n",
    "        ranks: ndarray\n",
    "            Ranks of the training data w.r.t. original ordering\n",
    "        ratings: ndarray\n",
    "            Ratings of the training data w.r.t. original ordering\n",
    "        epochs : int, default=1\n",
    "            The number of times to loop through the training data when fitting.\n",
    "        shuffle : bool, default True\n",
    "            Whether or not to randomize the order of train data when fitting.\n",
    "            Can be seeded with np.random.seed() prior to calling fit.\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "            Fits the SOM to the given data but does not return anything.\n",
    "        \"\"\"\n",
    "        topK = np.argsort(ranks)[:(self.m*self.n)]\n",
    "        self.expected_ratings = ratings[topK]\n",
    "        self.volume_of_samples = len(X)\n",
    "        \n",
    "        # Count total number of iterations\n",
    "        global_iter_counter = 0\n",
    "        n_samples = X.shape[0]\n",
    "        total_iterations = np.minimum(epochs * n_samples, self.max_iter)\n",
    "        \n",
    "        #prepare for probabilistic candidates selection\n",
    "        rngForCandidateSelection = np.random.default_rng(self.random_state)\n",
    "        prob = ratings/np.sum(ratings)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Break if past max number of iterations\n",
    "            if global_iter_counter > self.max_iter:\n",
    "                break\n",
    "            \n",
    "            if self.use_prob_candidate_selection:\n",
    "                indices = rngForCandidateSelection.choice(np.arange(n_samples) , size=n_samples, p=prob)             \n",
    "            elif shuffle:\n",
    "                rng = np.random.default_rng(self.random_state)\n",
    "                indices = rng.permutation(n_samples)\n",
    "            else:\n",
    "                indices = np.arange(n_samples)\n",
    "\n",
    "            # Train\n",
    "            for idx in indices:\n",
    "                # Break if past max number of iterations\n",
    "                if global_iter_counter > self.max_iter:\n",
    "                    break\n",
    "                input = X[idx]\n",
    "                rank = ranks[idx]\n",
    "                rating = ratings[idx]\n",
    "                # Do one step of training\n",
    "                self.step(input, rank, rating)\n",
    "                # Update learning rate\n",
    "                global_iter_counter += 1\n",
    "                self.lr = (1 - (global_iter_counter / total_iterations)) * self.initial_lr\n",
    "\n",
    "        # Compute inertia\n",
    "        inertia = np.sum(np.array([float(self._compute_point_intertia(x)) for x in X]))\n",
    "        self._inertia_ = inertia\n",
    "\n",
    "        # Set n_iter_ attribute\n",
    "        self._n_iter_ = global_iter_counter\n",
    "\n",
    "        # Set trained flag\n",
    "        self._trained = True\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, X, ranks, ratings):\n",
    "        \"\"\"\n",
    "        Predict cluster for each element in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            An ndarray of shape (n, self.dim) where n is the number of samples.\n",
    "            The data to predict clusters for.\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray\n",
    "            An ndarray of shape (n,). The predicted cluster index for each item\n",
    "            in X.\n",
    "        \"\"\"\n",
    "        # Check to make sure SOM has been fit\n",
    "        if not self._trained:\n",
    "            raise NotImplementedError('SOM object has no predict() method until after calling fit().')\n",
    "\n",
    "        # Make sure X has proper shape\n",
    "        assert len(X.shape) == 2, f'X should have two dimensions, not {len(X.shape)}'\n",
    "        assert X.shape[1] == self.dim, f'This SOM has dimesnion {self.dim}. Received input with dimension {X.shape[1]}'\n",
    "        \n",
    "        \n",
    "        indices = range(len(ranks))\n",
    "        labels = np.array([self._find_bmu(X[idx,:]) for idx in indices])\n",
    "        #if self.som_type == \"normal\":\n",
    "        #    labels = np.array([self._find_bmu(X[idx,:]) for idx in indices])\n",
    "        #elif self.som_type == \"rank\":\n",
    "        #    labels = np.array([self._find_bmu_rank_aware(X[idx,:], ranks[idx], ratings[idx]) for idx in indices])\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def transform(self, X, ranks, ratings):\n",
    "        \"\"\"\n",
    "        Transform the data X into cluster distance space.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            Data of shape (n, self.dim) where n is the number of samples. The\n",
    "            data to transform.\n",
    "        Returns\n",
    "        -------\n",
    "        transformed : ndarray\n",
    "            Transformed data of shape (n, self.n*self.m). The Euclidean distance\n",
    "            from each item in X to each cluster center.\n",
    "        \"\"\"\n",
    "        # Stack data and cluster centers\n",
    "        X_stack = np.stack([X]*(self.m*self.n), axis=1)\n",
    "        cluster_stack = np.stack([self.weights]*X.shape[0], axis=0)\n",
    "\n",
    "        # Compute difference\n",
    "        diff = X_stack - cluster_stack\n",
    "\n",
    "        # Take and return norm\n",
    "        return np.linalg.norm(diff, axis=2)\n",
    "\n",
    "    @property\n",
    "    def cluster_centers_(self):\n",
    "        return self.weights.reshape(self.m, self.n, self.dim)\n",
    "\n",
    "    @property\n",
    "    def inertia_(self):\n",
    "        if self._inertia_ is None:\n",
    "            raise AttributeError('SOM does not have inertia until after calling fit()')\n",
    "        return self._inertia_\n",
    "\n",
    "    @property\n",
    "    def n_iter_(self):\n",
    "        if self._n_iter_ is None:\n",
    "            raise AttributeError('SOM does not have n_iter_ attribute until after calling fit()')\n",
    "        return self._n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "- 20000 keyframes as in https://dl.acm.org/doi/10.1145/3372278.3390726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = pd.read_csv(\"native-queries/frame-ID-to-filepath.csv\",sep=' ',names=['filename', 'ID'])\n",
    "filepathsArray = filepaths.filename.to_numpy()\n",
    "\n",
    "query_scores = np.fromfile(\"native-queries/native-query-scores.bin\", dtype='f')\n",
    "query_scores = query_scores.reshape(327, 20000)\n",
    "\n",
    "frame_ids = np.fromfile(\"native-queries/native-query-frame-IDs.bin\", dtype='i')\n",
    "frame_ids = frame_ids.reshape(327, 20000)\n",
    "\n",
    "frame_features = np.fromfile(\"native-queries/frame-features.bin\", dtype='f')\n",
    "frame_features = frame_features.reshape(20000, 128)\n",
    "\n",
    "nativeQueries = pd.read_csv(\"native-queries/native-queries.csv\",sep=';',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.140000e+02, 3.512000e+03, 2.405700e+04, 2.377660e+05,\n",
       "        1.383429e+06, 8.012490e+05, 9.448200e+04, 1.257700e+04,\n",
       "        1.978000e+03, 6.360000e+02]),\n",
       " array([-0.59903127, -0.47379982, -0.34856838, -0.22333695, -0.09810551,\n",
       "         0.02712592,  0.15235737,  0.2775888 ,  0.40282023,  0.5280517 ,\n",
       "         0.6532831 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(frame_features.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  6, 10, 15, 21, 28,  2,  4,  7, 11, 16, 22, 29, 36,  5,\n",
       "        8, 12, 17, 23, 30, 37, 43,  9, 13, 18, 24, 31, 38, 44, 49, 14, 19,\n",
       "       25, 32, 39, 45, 50, 54, 20, 26, 33, 40, 46, 51, 55, 58, 27, 34, 41,\n",
       "       47, 52, 56, 59, 61, 35, 42, 48, 53, 57, 60, 62, 63])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getGoldenTriangleOrdering(size):\n",
    "    #get ordering of the golden triangle starting from top-left corner and going over second diagonal.\n",
    "    #having a 3x3 square, the ordering is [0,0], [0,1], [1,0], [0,2], [1,1], [2,0], [1,2], [2,1], [2,2]\n",
    "    maxIndexSum = size*2 -1\n",
    "    listOfIndices = []\n",
    "    \n",
    "    for n in range(maxIndexSum):\n",
    "        for i in range(size):\n",
    "            firstIndex = i\n",
    "            secondIndex = n-i\n",
    "            if secondIndex < size and secondIndex >= 0:\n",
    "                listOfIndices.append((firstIndex,secondIndex))\n",
    "    \n",
    " \n",
    "    mat = np.zeros((size,size),dtype=int)   \n",
    "    vals = np.array(range(size**2))\n",
    "\n",
    "    for i,idx in enumerate(listOfIndices):\n",
    "        mat[idx] = vals[i]\n",
    "    return mat\n",
    "indexMatrix = getGoldenTriangleOrdering(8)\n",
    "indexMatrix.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalProcessVBS():\n",
    "    \n",
    "    labels = {\n",
    "        \"normal\":\"Plain SOM\",\n",
    "        \"rating\":\"Rating SOM\",\n",
    "        \"rank\":\"Rank SOM\",\n",
    "        \"rank_pos\":\"DiscRank SOM\",\n",
    "        \"topk\":\"Top-K display\",\n",
    "        \n",
    "    }\n",
    "    \n",
    "    def __init__(self, som_variants, alphas,  display_mode, exponents, examples, path_to_image,  \n",
    "                 test_set_size, bias_std_dev, use_triangular):          \n",
    "        self.SOM_dim = 8\n",
    "        \n",
    "        self.som_variants = som_variants\n",
    "        self.alphas = alphas\n",
    "        self.display_mode = display_mode\n",
    "        self.exponents = exponents\n",
    "        self.use_triangular = use_triangular\n",
    "        self.bias_std_dev = bias_std_dev\n",
    "        self.use_prob_candidate_selections = [False,True]        \n",
    "         \n",
    "        self.unbiasedSamples = examples\n",
    "        self.path_to_image = path_to_image\n",
    "        \n",
    "        self.test_size = test_set_size\n",
    "\n",
    "        \n",
    "        np.random.seed(10)\n",
    "        self.testTargetIDs = np.random.choice(self.unbiasedSamples.shape[0],self.test_size)\n",
    "        self.testTargets = self.unbiasedSamples[self.testTargetIDs,:]     \n",
    "        \n",
    "        \n",
    "    def _evaluateTestSampleRating(self):\n",
    "        \"\"\"\n",
    "        evaluates rating and ranking between sample objects and test objects\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.seed(42)\n",
    "        samples = self.unbiasedSamples\n",
    "        \n",
    "        self.pairwiseSampleDistances = euclidean_distances(samples) \n",
    "        unbiasedDistance = euclidean_distances(samples, self.testTargets) \n",
    "        \n",
    "        self.unbiasedRatings = np.exp(-self.exponent*unbiasedDistance)\n",
    "        #self.unbiasedRatings = ((2-unbiasedDistance)/2)**self.exponent\n",
    "        \n",
    "        if self.bias_std_dev >0:\n",
    "            #bias = np.random.normal(0.0, self.bias_std_dev, size=self.unbiasedSamples.shape)\n",
    "            #samples = self.unbiasedSamples+bias\n",
    "        \n",
    "            bias = np.random.normal(0.0, self.bias_std_dev, size=self.testTargets.shape)\n",
    "            testTargets = self.testTargets+bias\n",
    "            \n",
    "        self.samples = samples #using biased samples to order stuf\n",
    "        \n",
    "        distance = euclidean_distances(samples, testTargets)        \n",
    "\n",
    "        self.ratings = np.exp(-self.exponent*distance)\n",
    "        self.ratings = self.ratings/np.max(self.ratings)\n",
    "        #self.ratings = ((2-distance)/2)**self.exponent\n",
    "        \n",
    "        ranks = []\n",
    "        temp = distance.argsort(axis=0)\n",
    "        for i in range(self.test_size):\n",
    "            rank = np.empty_like(temp[:,i])\n",
    "\n",
    "            rank[temp[:,i]] = np.arange(distance.shape[0])\n",
    "            ranks.append(rank)\n",
    "        self.ranks = np.stack(ranks, axis=-1)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "    def runConfigurations(self): \n",
    "        resultingIDX = {}\n",
    "        ratings = {}\n",
    "        ratingsUnbiased = {} \n",
    "        for e in self.exponents:\n",
    "            self.exponent = e\n",
    "            # calculate rating and ranking for individual test cases and sample data\n",
    "            self._evaluateTestSampleRating()\n",
    "            \n",
    "            for a in self.alphas:\n",
    "                print(\"alpha: \"+str(a)+\" exponent:\"+str(e))\n",
    "                for i in range(self.test_size):\n",
    "                    if i%10 == 0:\n",
    "                        print(\"test-case: \"+str(i))\n",
    "                    for pcs in self.use_prob_candidate_selections:                    \n",
    "                        self.use_prob_candidate_selection = pcs\n",
    "                        numOfVariants = len(self.som_variants)\n",
    "\n",
    "                        for idx,sv in enumerate(self.som_variants):\n",
    "                            if a > self.alphas[0] and (sv == \"normal\" or sv ==\"topk\"):\n",
    "                                continue #run plain som and topk only once\n",
    "                            if e != self.exponents[2] and pcs == False:\n",
    "                                continue # only one variant of exponent for non-probabilistic approaches\n",
    "\n",
    "                            (displayedIDXs,displayedRatings,displayedUnbiasedRatings) = self.runOneStep(a, sv, i)\n",
    "                            resultingIDX[(a,i,sv,e,self.display_mode,self.use_triangular,self.use_prob_candidate_selection)] = displayedIDXs\n",
    "                            ratings[(a,i,sv,e,self.display_mode,self.use_triangular,self.use_prob_candidate_selection)] = displayedRatings\n",
    "                            ratingsUnbiased[(a,i,sv,e,self.display_mode,self.use_triangular,self.use_prob_candidate_selection)] = displayedUnbiasedRatings\n",
    "\n",
    "\n",
    "        return (resultingIDX,ratings,ratingsUnbiased)\n",
    "              \n",
    "            \n",
    "    def runOneStep(self, alpha, som_variant, testIndex):  \n",
    "        #fig,ax = plt.subplots(1,1)\n",
    "        #testPath = self.path_to_image[self.testTargetIDs[testIndex]]\n",
    "        #self.displayOneElement(ax, testPath) \n",
    "        \n",
    "        #print(alpha, som_variant, testIndex, self.use_prob_candidate_selection)\n",
    "        if self.display_mode == \"topk\":   \n",
    "            if som_variant == \"topk\":\n",
    "                (displayedIDXs,displayedRatings) = self.displayTopKForTopK(\n",
    "                    self.testTargets[testIndex], self.ratings[:,testIndex], \n",
    "                    self.ranks[:,testIndex], som_variant, alpha, self.use_triangular, self.use_prob_candidate_selection)   \n",
    "            else:\n",
    "                (displayedIDXs,displayedRatings) = self.displayTopKForRankSOM(\n",
    "                    self.testTargets[testIndex], self.ratings[:,testIndex], \n",
    "                    self.ranks[:,testIndex], som_variant, alpha, self.use_triangular, self.use_prob_candidate_selection)\n",
    "                \n",
    "            displayedUnbiasedRatings = self.unbiasedRatings[displayedIDXs,testIndex]                   \n",
    "            \n",
    "        return (displayedIDXs,displayedRatings,displayedUnbiasedRatings)\n",
    "     \n",
    "        \n",
    "\n",
    "    def displayOneElement(self, ax, path):\n",
    "        directory = \"native-queries/thumbs/\"\n",
    "        img = Image.open(directory + path)\n",
    "        img = img.resize((128, 72))\n",
    "        img = np.asarray(img)\n",
    "        ax.imshow(img)\n",
    "        self.finalizeImage(ax) \n",
    "        \n",
    "    \n",
    "    def finalizeImage(self, ax):\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.margins(0.0)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        \n",
    "    def displayTopKForRankSOM(self, target, ratings, rankings, som_type, alpha, use_triangular, use_prob_candidate_selection):\n",
    "        \n",
    "        vbs_som = SOM(m=self.SOM_dim, n=self.SOM_dim, dim=128, random_state=42, max_iter=40000, \n",
    "                        som_type=som_type, alpha=alpha, use_triangular=use_triangular, \n",
    "                        use_prob_candidate_selection = use_prob_candidate_selection)        \n",
    "        vbs_som.fit(self.samples, rankings, ratings, epochs=10)\n",
    "        \n",
    "        linearized_indexes = vbs_som.predict(self.samples, rankings, ratings)\n",
    "        indexes = np.unravel_index(linearized_indexes,(self.SOM_dim,self.SOM_dim))\n",
    "        \n",
    "        allGridPositions = np.arange(self.SOM_dim**2)\n",
    "        \n",
    "        idxToDisplay = []\n",
    "        for i in allGridPositions:\n",
    "            clusterGroup = (linearized_indexes == i).nonzero()[0]\n",
    "            clusterGroup = [i for i in clusterGroup if i not in idxToDisplay]\n",
    "            if len(clusterGroup) > 0:     \n",
    "                #non-empty cluster, get top-k element\n",
    "                idx = np.arange(ratings.size)[clusterGroup]\n",
    "                idxToDisplay.append(idx[np.argmax(ratings[idx])])\n",
    "            else:\n",
    "                #empty cluster, finding closest not yet used image to the cluster centre\n",
    "                clusterCentre = vbs_som.weights[i]\n",
    "                distanceToClusterCentre = euclidean_distances(self.samples, clusterCentre.reshape(-1,128)).reshape(-1)\n",
    "                sortedDistances = np.argsort(distanceToClusterCentre) \n",
    "                sortedDistances = [i for i in sortedDistances if i not in idxToDisplay]\n",
    "                idxToDisplay.append(sortedDistances[0])\n",
    "        #print(np.unique(idxToDisplay).shape)\n",
    "        \n",
    "        displayedIDXs = []\n",
    "        displayedRatings = []\n",
    "        \n",
    "        #fig,ax= plt.subplots(self.SOM_dim,self.SOM_dim, figsize=(self.SOM_dim*2,self.SOM_dim*2*0.5625))\n",
    "        \n",
    "        for i, idx in enumerate(idxToDisplay):\n",
    "            #x = i // self.SOM_dim\n",
    "            #y = i % self.SOM_dim \n",
    "            #pathToImage = self.path_to_image[idx]\n",
    "            \n",
    "            displayedIDXs.append(idx)\n",
    "            displayedRatings.append(ratings[idx])\n",
    "            \n",
    "            #self.displayOneElement(ax[x, y], pathToImage) \n",
    "            \n",
    "        #plt.tight_layout(pad=0.0)\n",
    "        \n",
    "        return displayedIDXs,displayedRatings        \n",
    "        \n",
    "\n",
    "        \n",
    "    def displayTopKForTopK(self, target, ratings, rankings, som_type, alpha, use_triangular, use_prob_candidate_selection):\n",
    "        topkIndeces = np.argsort(rankings)[0:(self.SOM_dim*self.SOM_dim)]\n",
    "        if use_triangular:\n",
    "            ordering = getGoldenTriangleOrdering(self.SOM_dim).reshape(-1)\n",
    "            topkIndeces = topkIndeces[ordering]        \n",
    "        \n",
    "        #fig,ax= plt.subplots(self.SOM_dim,self.SOM_dim, figsize=(self.SOM_dim*2,self.SOM_dim*2*0.5625))\n",
    "\n",
    "        displayedIDXs = []\n",
    "        displayedRanks = []\n",
    "        displayedRatings = []\n",
    "        \n",
    "        for i,idx in enumerate(topkIndeces):\n",
    "            #x = i // self.SOM_dim\n",
    "            #y = i % self.SOM_dim            \n",
    "            #pathToImage = self.path_to_image[idx]\n",
    "            \n",
    "            displayedIDXs.append(idx)\n",
    "            displayedRatings.append(ratings[idx])\n",
    "\n",
    "            #self.displayOneElement(ax[x, y], pathToImage)\n",
    "\n",
    "        #plt.tight_layout(pad=0.0)\n",
    "        \n",
    "        return displayedIDXs,displayedRatings       \n",
    "\n",
    "def processData(dataDict):\n",
    "        resultsDF = pd.DataFrame.from_dict(dataDict, orient=\"index\", columns=[\"r\"+str(i) for i in list(range(1,65))])\n",
    "        resultsDF.index = pd.MultiIndex.from_tuples(resultsDF.index, names=('alpha', 'item',\"som_variant\",\"exponent\",\"display_mode\",\"use_triangular\",\"use_prob_candidate_selection\"))\n",
    "        resultsDF = resultsDF.reset_index()                        \n",
    "        #resultsDF[list(range(1,65))] = pd.DataFrame(resultsDF.results.tolist(), index=resultsDF.index)\n",
    "        #resultsDF.drop(\"results\",axis=1, inplace=True)\n",
    "        resultsDF[\"mean\"] = resultsDF[[\"r\"+str(i) for i in list(range(1,65))]].mean(axis=1)\n",
    "        #print(resultsDF.groupby(\"som_variant\")[\"mean\"].mean())\n",
    "        \n",
    "        return resultsDF       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0003 exponent:5\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n",
      "alpha: 0.001 exponent:5\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n",
      "alpha: 0.003 exponent:5\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n",
      "alpha: 0.0003 exponent:20\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n",
      "alpha: 0.001 exponent:20\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n",
      "alpha: 0.003 exponent:20\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n",
      "alpha: 0.0003 exponent:10\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n",
      "alpha: 0.001 exponent:10\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n",
      "alpha: 0.003 exponent:10\n",
      "test-case: 0\n",
      "test-case: 10\n",
      "test-case: 20\n",
      "test-case: 30\n",
      "test-case: 40\n",
      "test-case: 50\n",
      "test-case: 60\n",
      "test-case: 70\n",
      "test-case: 80\n",
      "test-case: 90\n"
     ]
    }
   ],
   "source": [
    "evalProc = EvalProcessVBS([\"rating\",\"normal\",\"topk\"], #,\"rating\",\"normal\",\"topk\"\"rank\",\"rank_pos\"\n",
    "                       [0.0003, 0.001, 0.003], #[0.0001, 0.001, 0.003, 0.01, 0.03, 0.1, 0.2, 0.5, 0.8, 0.9], 3e-9, 1e-8, 3e-8, 1e-7, 3e-7, 1e-6, 3e-6, 1e-5, 3e-5\n",
    "                       \"topk\", \n",
    "                       [5,20,10],#[5,20,10],\n",
    "                       frame_features, \n",
    "                       filepathsArray,\n",
    "                       100, \n",
    "                       0.2, \n",
    "                       True)\n",
    "(resultingIDX,ratings,ratingsUnbiased) = evalProc.runConfigurations()\n",
    "\n",
    "import pickle\n",
    "ratingsDF = processData(ratings)\n",
    "ratingsUnbDF = processData(ratingsUnbiased)\n",
    "resultingIDXDF = processData(resultingIDX)\n",
    "\n",
    "pickle.dump(evalProc,open(\"pck/evalProcVBSf3\"+\"_disp\"+str(evalProc.display_mode)+\"_triag\"+str(evalProc.use_triangular)+\".pck\", \"wb\"))\n",
    "ratingsDF.to_pickle(\"pck/ratingsDFVBSf3\"+\"_disp\"+str(evalProc.display_mode)+\"_triag\"+str(evalProc.use_triangular)+\".pck\")\n",
    "ratingsUnbDF.to_pickle(\"pck/ratingsUnbDFVBSf3\"+\"_disp\"+str(evalProc.display_mode)+\"_triag\"+str(evalProc.use_triangular)+\".pck\")\n",
    "resultingIDXDF.to_pickle(\"pck/resultingIDXDFVBSf3\"+\"_disp\"+str(evalProc.display_mode)+\"_triag\"+str(evalProc.use_triangular)+\".pck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "evalProc = pickle.load(open(\"pck/evalProcVBSf3_disptopk_triagTrue.pck\", \"rb\"))\n",
    "ratingsDF = pickle.load(open(\"pck/ratingsDFVBSf3_disptopk_triagTrue.pck\", \"rb\"))\n",
    "ratingsUnbDF = pickle.load(open(\"pck/ratingsUnbDFVBSf3_disptopk_triagTrue.pck\", \"rb\"))\n",
    "resultingIDXDF = pickle.load(open(\"pck/resultingIDXDFVBSf3_disptopk_triagTrue.pck\", \"rb\"))\n",
    "\n",
    "#evalProc = pickle.load(open(\"pck/evalProcVBS_disptopk_triagFalse.pck\", \"rb\"))\n",
    "#ratingsDF = pickle.load(open(\"pck/ratingsDFVBS_disptopk_triagFalse.pck\", \"rb\"))\n",
    "#ratingsUnbDF = pickle.load(open(\"pck/ratingsUnbDFVBS_disptopk_triagFalse.pck\", \"rb\"))\n",
    "#resultingIDXDF = pickle.load(open(\"pck/resultingIDXDFVBS_disptopk_triagFalse.pck\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateNDCG(idsDisplayed, ratingsAll, use_triangular, SOM_dim):\n",
    "    DCGPenalty = 1/np.log2(np.array(range(SOM_dim**2))+2)\n",
    "    if use_triangular:\n",
    "        dcgOrdering = getGoldenTriangleOrdering(SOM_dim).reshape(-1)\n",
    "        DCGPenalty = DCGPenalty[dcgOrdering]\n",
    "    positions = [\"r\"+str(i) for i in list(range(1,SOM_dim**2+1))]    \n",
    "    \n",
    "    dataIdeal = ratingsAll[:,idsDisplayed.item].T\n",
    "    topkIDX = np.argsort(-dataIdeal, axis=1)[:,0:SOM_dim**2]\n",
    "    \n",
    "    if use_triangular:\n",
    "        topkIDX = topkIDX[:,dcgOrdering] \n",
    "        \n",
    "    bestRatings = []\n",
    "    for i in range(topkIDX.shape[0]):\n",
    "        bestRatings.append(np.take(dataIdeal[i], topkIDX[i]))\n",
    "    bestRatingsArr = np.stack(bestRatings) \n",
    "    \n",
    "    \n",
    "    ids = idsDisplayed[positions].to_numpy()\n",
    "    receivedRatings = []\n",
    "    for i in range(topkIDX.shape[0]):\n",
    "        receivedRatings.append(np.take(dataIdeal[i], ids[i]))\n",
    "    receivedRatings = np.stack(receivedRatings)     \n",
    "    \n",
    "    iDCG = np.sum(bestRatingsArr*DCGPenalty, axis=1)\n",
    "    DCG = np.sum(receivedRatings*DCGPenalty, axis=1)\n",
    "    nDCG = DCG/iDCG\n",
    "    \n",
    "    return nDCG\n",
    "\n",
    "def calculateOverallDiversity(displayedIDX, distances, SOM_dim):\n",
    "    positions = [\"r\"+str(i) for i in list(range(1,SOM_dim**2+1))]    \n",
    "    \n",
    "    data = displayedIDX[positions]\n",
    "    df2 = pd.DataFrame(index=data.index)\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        for j in range(i+1,data.shape[1]):\n",
    "            df2[\"d_\"+str(i+1)+\"_\"+str(j+1)] = distances[data[\"r\"+str(i+1)],data[\"r\"+str(j+1)]]\n",
    "    return df2.mean(axis=1),df2.max(axis=1) \n",
    "\n",
    "def neighbors(i, SOM_dim):\n",
    "    minVal = 0\n",
    "    maxVal = SOM_dim - 1\n",
    "    vals = []\n",
    "    ii = i // SOM_dim\n",
    "    ij = i % SOM_dim\n",
    "    for a in [-1,0,1]:\n",
    "        for b in [-1,0,1]:\n",
    "            if ii+a >= minVal and ij+b >= minVal and ii+a <= maxVal and ij+b <= maxVal:\n",
    "                val = (ii+a)*SOM_dim + ij+b\n",
    "                if val != i:\n",
    "                    vals.append(val) \n",
    "    return vals\n",
    "            \n",
    "\n",
    "def calculateNeighborsDiversity(displayedIDX, distances, SOM_dim):\n",
    "    positions = [\"r\"+str(i) for i in list(range(1,SOM_dim**2+1))]    \n",
    "    \n",
    "    data = displayedIDX[positions]\n",
    "    df2 = pd.DataFrame(index=data.index)\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        for j in neighbors(i,SOM_dim):\n",
    "            #print(i,j)\n",
    "            df2[\"d_\"+str(i+1)+\"_\"+str(j+1)] = distances[data[\"r\"+str(i+1)],data[\"r\"+str(j+1)]]\n",
    "    return df2.mean(axis=1),df2.max(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-03bc8221dfd5>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[\"d_\"+str(i+1)+\"_\"+str(j+1)] = distances[data[\"r\"+str(i+1)],data[\"r\"+str(j+1)]]\n",
      "<ipython-input-25-03bc8221dfd5>:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[\"d_\"+str(i+1)+\"_\"+str(j+1)] = distances[data[\"r\"+str(i+1)],data[\"r\"+str(j+1)]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>item</th>\n",
       "      <th>som_variant</th>\n",
       "      <th>exponent</th>\n",
       "      <th>display_mode</th>\n",
       "      <th>use_triangular</th>\n",
       "      <th>use_prob_candidate_selection</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>...</th>\n",
       "      <th>r62</th>\n",
       "      <th>r63</th>\n",
       "      <th>r64</th>\n",
       "      <th>mean</th>\n",
       "      <th>meanNeighborDiversity</th>\n",
       "      <th>maxNeighborDiversity</th>\n",
       "      <th>meanOverallDiversity</th>\n",
       "      <th>maxDiversity</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>neighborOverallRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0</td>\n",
       "      <td>rating</td>\n",
       "      <td>5</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>357</td>\n",
       "      <td>17673</td>\n",
       "      <td>11458</td>\n",
       "      <td>...</td>\n",
       "      <td>12872</td>\n",
       "      <td>3597</td>\n",
       "      <td>14903</td>\n",
       "      <td>9549.187500</td>\n",
       "      <td>1.047539</td>\n",
       "      <td>1.527019</td>\n",
       "      <td>1.113504</td>\n",
       "      <td>1.527019</td>\n",
       "      <td>0.629588</td>\n",
       "      <td>0.940760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>5</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>730</td>\n",
       "      <td>16920</td>\n",
       "      <td>11548</td>\n",
       "      <td>...</td>\n",
       "      <td>10139</td>\n",
       "      <td>19921</td>\n",
       "      <td>1362</td>\n",
       "      <td>10362.281250</td>\n",
       "      <td>1.234605</td>\n",
       "      <td>1.525848</td>\n",
       "      <td>1.327593</td>\n",
       "      <td>1.562400</td>\n",
       "      <td>0.249078</td>\n",
       "      <td>0.929957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0</td>\n",
       "      <td>topk</td>\n",
       "      <td>5</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>357</td>\n",
       "      <td>17673</td>\n",
       "      <td>1362</td>\n",
       "      <td>...</td>\n",
       "      <td>5876</td>\n",
       "      <td>10595</td>\n",
       "      <td>7837</td>\n",
       "      <td>9746.328125</td>\n",
       "      <td>0.989131</td>\n",
       "      <td>1.319252</td>\n",
       "      <td>0.983205</td>\n",
       "      <td>1.337008</td>\n",
       "      <td>0.629867</td>\n",
       "      <td>1.006027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>1</td>\n",
       "      <td>rating</td>\n",
       "      <td>5</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7293</td>\n",
       "      <td>17441</td>\n",
       "      <td>15142</td>\n",
       "      <td>...</td>\n",
       "      <td>18008</td>\n",
       "      <td>3635</td>\n",
       "      <td>18318</td>\n",
       "      <td>10797.453125</td>\n",
       "      <td>1.067256</td>\n",
       "      <td>1.527019</td>\n",
       "      <td>1.137460</td>\n",
       "      <td>1.581404</td>\n",
       "      <td>0.998637</td>\n",
       "      <td>0.938280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>5</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>14579</td>\n",
       "      <td>18008</td>\n",
       "      <td>8772</td>\n",
       "      <td>...</td>\n",
       "      <td>11959</td>\n",
       "      <td>7483</td>\n",
       "      <td>4523</td>\n",
       "      <td>10157.203125</td>\n",
       "      <td>1.211815</td>\n",
       "      <td>1.490036</td>\n",
       "      <td>1.305404</td>\n",
       "      <td>1.519833</td>\n",
       "      <td>0.176029</td>\n",
       "      <td>0.928306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>97</td>\n",
       "      <td>rating</td>\n",
       "      <td>10</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>11315</td>\n",
       "      <td>8728</td>\n",
       "      <td>19709</td>\n",
       "      <td>...</td>\n",
       "      <td>16667</td>\n",
       "      <td>11081</td>\n",
       "      <td>191</td>\n",
       "      <td>10149.625000</td>\n",
       "      <td>1.148949</td>\n",
       "      <td>1.429950</td>\n",
       "      <td>1.182410</td>\n",
       "      <td>1.546167</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.971701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>98</td>\n",
       "      <td>rating</td>\n",
       "      <td>10</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5233</td>\n",
       "      <td>10406</td>\n",
       "      <td>4616</td>\n",
       "      <td>...</td>\n",
       "      <td>14003</td>\n",
       "      <td>14103</td>\n",
       "      <td>4219</td>\n",
       "      <td>9887.718750</td>\n",
       "      <td>1.146502</td>\n",
       "      <td>1.555914</td>\n",
       "      <td>1.321172</td>\n",
       "      <td>1.591368</td>\n",
       "      <td>0.217857</td>\n",
       "      <td>0.867792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>98</td>\n",
       "      <td>rating</td>\n",
       "      <td>10</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>17487</td>\n",
       "      <td>19275</td>\n",
       "      <td>19614</td>\n",
       "      <td>...</td>\n",
       "      <td>13368</td>\n",
       "      <td>5748</td>\n",
       "      <td>17319</td>\n",
       "      <td>10318.703125</td>\n",
       "      <td>1.154780</td>\n",
       "      <td>1.506311</td>\n",
       "      <td>1.243777</td>\n",
       "      <td>1.506311</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.928447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>99</td>\n",
       "      <td>rating</td>\n",
       "      <td>10</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13073</td>\n",
       "      <td>1064</td>\n",
       "      <td>16558</td>\n",
       "      <td>...</td>\n",
       "      <td>2990</td>\n",
       "      <td>12536</td>\n",
       "      <td>49</td>\n",
       "      <td>10288.140625</td>\n",
       "      <td>1.205158</td>\n",
       "      <td>1.502697</td>\n",
       "      <td>1.330149</td>\n",
       "      <td>1.576892</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.906032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>99</td>\n",
       "      <td>rating</td>\n",
       "      <td>10</td>\n",
       "      <td>topk</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>13073</td>\n",
       "      <td>17898</td>\n",
       "      <td>3342</td>\n",
       "      <td>...</td>\n",
       "      <td>10515</td>\n",
       "      <td>3060</td>\n",
       "      <td>17508</td>\n",
       "      <td>9341.031250</td>\n",
       "      <td>1.208626</td>\n",
       "      <td>1.457340</td>\n",
       "      <td>1.307086</td>\n",
       "      <td>1.526548</td>\n",
       "      <td>0.999230</td>\n",
       "      <td>0.924673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha  item som_variant  exponent display_mode  use_triangular  \\\n",
       "0     0.0003     0      rating         5         topk            True   \n",
       "1     0.0003     0      normal         5         topk            True   \n",
       "2     0.0003     0        topk         5         topk            True   \n",
       "3     0.0003     1      rating         5         topk            True   \n",
       "4     0.0003     1      normal         5         topk            True   \n",
       "...      ...   ...         ...       ...          ...             ...   \n",
       "1995  0.0030    97      rating        10         topk            True   \n",
       "1996  0.0030    98      rating        10         topk            True   \n",
       "1997  0.0030    98      rating        10         topk            True   \n",
       "1998  0.0030    99      rating        10         topk            True   \n",
       "1999  0.0030    99      rating        10         topk            True   \n",
       "\n",
       "      use_prob_candidate_selection     r1     r2     r3  ...    r62    r63  \\\n",
       "0                             True    357  17673  11458  ...  12872   3597   \n",
       "1                             True    730  16920  11548  ...  10139  19921   \n",
       "2                             True    357  17673   1362  ...   5876  10595   \n",
       "3                             True   7293  17441  15142  ...  18008   3635   \n",
       "4                             True  14579  18008   8772  ...  11959   7483   \n",
       "...                            ...    ...    ...    ...  ...    ...    ...   \n",
       "1995                          True  11315   8728  19709  ...  16667  11081   \n",
       "1996                         False   5233  10406   4616  ...  14003  14103   \n",
       "1997                          True  17487  19275  19614  ...  13368   5748   \n",
       "1998                         False  13073   1064  16558  ...   2990  12536   \n",
       "1999                          True  13073  17898   3342  ...  10515   3060   \n",
       "\n",
       "        r64          mean  meanNeighborDiversity  maxNeighborDiversity  \\\n",
       "0     14903   9549.187500               1.047539              1.527019   \n",
       "1      1362  10362.281250               1.234605              1.525848   \n",
       "2      7837   9746.328125               0.989131              1.319252   \n",
       "3     18318  10797.453125               1.067256              1.527019   \n",
       "4      4523  10157.203125               1.211815              1.490036   \n",
       "...     ...           ...                    ...                   ...   \n",
       "1995    191  10149.625000               1.148949              1.429950   \n",
       "1996   4219   9887.718750               1.146502              1.555914   \n",
       "1997  17319  10318.703125               1.154780              1.506311   \n",
       "1998     49  10288.140625               1.205158              1.502697   \n",
       "1999  17508   9341.031250               1.208626              1.457340   \n",
       "\n",
       "      meanOverallDiversity  maxDiversity      nDCG  neighborOverallRatio  \n",
       "0                 1.113504      1.527019  0.629588              0.940760  \n",
       "1                 1.327593      1.562400  0.249078              0.929957  \n",
       "2                 0.983205      1.337008  0.629867              1.006027  \n",
       "3                 1.137460      1.581404  0.998637              0.938280  \n",
       "4                 1.305404      1.519833  0.176029              0.928306  \n",
       "...                    ...           ...       ...                   ...  \n",
       "1995              1.182410      1.546167  0.999405              0.971701  \n",
       "1996              1.321172      1.591368  0.217857              0.867792  \n",
       "1997              1.243777      1.506311  0.998811              0.928447  \n",
       "1998              1.330149      1.576892  0.999198              0.906032  \n",
       "1999              1.307086      1.526548  0.999230              0.924673  \n",
       "\n",
       "[2000 rows x 78 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanDistN, maxDistN = calculateNeighborsDiversity(resultingIDXDF, evalProc.pairwiseSampleDistances, evalProc.SOM_dim)\n",
    "resultingIDXDF[\"meanNeighborDiversity\"]  =  meanDistN \n",
    "resultingIDXDF[\"maxNeighborDiversity\"]  =  maxDistN \n",
    "meanDist, maxDist = calculateOverallDiversity(resultingIDXDF, evalProc.pairwiseSampleDistances, evalProc.SOM_dim)\n",
    "resultingIDXDF[\"meanOverallDiversity\"]  =  meanDist \n",
    "resultingIDXDF[\"maxDiversity\"]  =  maxDist \n",
    "ratingsUnbDF[\"nDCG\"] = calculateNDCG(resultingIDXDF, evalProc.unbiasedRatings, evalProc.use_triangular, evalProc.SOM_dim)\n",
    "resultingIDXDF[\"nDCG\"] = ratingsUnbDF[\"nDCG\"]\n",
    "resultingIDXDF[\"neighborOverallRatio\"] = resultingIDXDF.meanNeighborDiversity / resultingIDXDF.meanOverallDiversity\n",
    "meanRes = resultingIDXDF.groupby([\"alpha\",\"som_variant\",\"use_prob_candidate_selection\",\"exponent\"])[[\"nDCG\",\"meanOverallDiversity\",\"meanNeighborDiversity\"]].mean()\n",
    "meanRes[\"neighborOverallRatio\"] = meanRes.meanNeighborDiversity / meanRes.meanOverallDiversity\n",
    "resultingIDXDF\n",
    "#resultingIDXDF.groupby([\"alpha\",\"som_variant\"])[\"meanNeighborDiversity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "meanResReduced = meanRes.loc[idx[:, [\"normal\",\"topk\",\"rating\"],:,:], :]\n",
    "meanResReduced = meanResReduced.drop(meanResReduced.loc[idx[:, \"topk\",True,:],:].index)\n",
    "#meanResReduced = meanResReduced.drop(meanResReduced.loc[idx[:,:,:, 20],:].index)\n",
    "#meanResReduced = meanResReduced.drop(meanResReduced.loc[idx[[0.003, 0.01,0.03,0.1,0.2,0.5,0.8,0.9], [\"normal\",\"topk\"],:,:],:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ax = sns.scatterplot(x=meanResReduced.nDCG.values, y=meanResReduced.meanOverallDiversity.values, \n",
    "                hue=meanResReduced.neighborOverallRatio.values, \n",
    "                style = zip(meanResReduced.index.get_level_values(1),meanResReduced.index.get_level_values(3),meanResReduced.index.get_level_values(2)),\n",
    "                palette='RdBu',s=80)\n",
    "\n",
    "norm = plt.Normalize(meanRes.neighborOverallRatio.min(), meanRes.neighborOverallRatio.max())\n",
    "#meanRes.neighborOverallRatio.min(), meanRes.neighborOverallRatio.max()\n",
    "sm = plt.cm.ScalarMappable(cmap=\"RdBu\", norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labelsDict = {\n",
    "   \"('rating', 10, False)\": \"Rating SOM\", \n",
    "    \"('rating', 5, True)\": \"Rating SOM+Prob, exp:5\", \n",
    "    \"('rating', 10, True)\": \"Rating SOM+Prob, exp:10\", \n",
    "    \"('rating', 20, True)\": \"Rating SOM+Prob, exp:20\", \n",
    "    \"('normal', 10, False)\": \"Plain SOM\", \n",
    "    \"('normal', 5, True)\": \"Plain SOM+Prob, exp:5\", \n",
    "    \"('normal', 10, True)\": \"Plain SOM+Prob, exp:10\", \n",
    "    \"('normal', 20, True)\": \"Plain SOM+Prob, exp:20\", \n",
    "    \n",
    "    \"('topk', 10, False)\": \"Top-k\"     \n",
    "}\n",
    "lbls = [labelsDict.get(i,i) for i in labels[-9:]]\n",
    "ax.legend(handles=handles[-9:], labels=lbls, loc=3)\n",
    "ax.set_xlabel(\"Ordering relevance (nDCG)\")\n",
    "ax.set_ylabel(\"Overall Diversity\")\n",
    "\n",
    "ax.figure.colorbar(sm, label=\"Neighbors vs. Overall Diversity Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"VBS_noTriangle.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalProc2 = pickle.load(open(\"pck/evalProcVBSf2_disptopk_triagTrue.pck\", \"rb\"))\n",
    "ratingsDF2 = pickle.load(open(\"pck/ratingsDFVBSf2_disptopk_triagTrue.pck\", \"rb\"))\n",
    "ratingsUnbDF2 = pickle.load(open(\"pck/ratingsUnbDFVBSf2_disptopk_triagTrue.pck\", \"rb\"))\n",
    "resultingIDXDF2 = pickle.load(open(\"pck/resultingIDXDFVBSf2_disptopk_triagTrue.pck\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-03bc8221dfd5>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[\"d_\"+str(i+1)+\"_\"+str(j+1)] = distances[data[\"r\"+str(i+1)],data[\"r\"+str(j+1)]]\n",
      "<ipython-input-8-03bc8221dfd5>:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[\"d_\"+str(i+1)+\"_\"+str(j+1)] = distances[data[\"r\"+str(i+1)],data[\"r\"+str(j+1)]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nDCG</th>\n",
       "      <th>meanOverallDiversity</th>\n",
       "      <th>meanNeighborDiversity</th>\n",
       "      <th>neighborOverallRatio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>som_variant</th>\n",
       "      <th>use_prob_candidate_selection</th>\n",
       "      <th>exponent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.01</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">normal</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.199587</td>\n",
       "      <td>1.322132</td>\n",
       "      <td>1.243279</td>\n",
       "      <td>0.940359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.210502</td>\n",
       "      <td>1.314791</td>\n",
       "      <td>1.223740</td>\n",
       "      <td>0.930748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.200902</td>\n",
       "      <td>1.301962</td>\n",
       "      <td>1.202991</td>\n",
       "      <td>0.923983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.264382</td>\n",
       "      <td>1.253461</td>\n",
       "      <td>1.133690</td>\n",
       "      <td>0.904448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topk</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.826294</td>\n",
       "      <td>1.146293</td>\n",
       "      <td>1.143876</td>\n",
       "      <td>0.997892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.260245</td>\n",
       "      <td>1.326315</td>\n",
       "      <td>1.200821</td>\n",
       "      <td>0.905382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.295835</td>\n",
       "      <td>1.277797</td>\n",
       "      <td>1.160046</td>\n",
       "      <td>0.907849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.708222</td>\n",
       "      <td>1.264255</td>\n",
       "      <td>1.152093</td>\n",
       "      <td>0.911282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.586526</td>\n",
       "      <td>1.240876</td>\n",
       "      <td>1.124177</td>\n",
       "      <td>0.905954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.03</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.213218</td>\n",
       "      <td>1.322426</td>\n",
       "      <td>1.211512</td>\n",
       "      <td>0.916128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.522217</td>\n",
       "      <td>1.292314</td>\n",
       "      <td>1.164219</td>\n",
       "      <td>0.900879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.643513</td>\n",
       "      <td>1.275581</td>\n",
       "      <td>1.162984</td>\n",
       "      <td>0.911729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.480604</td>\n",
       "      <td>1.246666</td>\n",
       "      <td>1.128180</td>\n",
       "      <td>0.904958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.10</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.192456</td>\n",
       "      <td>1.321468</td>\n",
       "      <td>1.225182</td>\n",
       "      <td>0.927137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.490519</td>\n",
       "      <td>1.302408</td>\n",
       "      <td>1.187926</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.443158</td>\n",
       "      <td>1.291421</td>\n",
       "      <td>1.185181</td>\n",
       "      <td>0.917734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.410681</td>\n",
       "      <td>1.251601</td>\n",
       "      <td>1.132241</td>\n",
       "      <td>0.904634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             nDCG  \\\n",
       "alpha som_variant use_prob_candidate_selection exponent             \n",
       "0.01  normal      False                        10        0.199587   \n",
       "                  True                         5         0.210502   \n",
       "                                               10        0.200902   \n",
       "                                               20        0.264382   \n",
       "      topk        False                        10        0.826294   \n",
       "      rating      False                        10        0.260245   \n",
       "                  True                         5         0.295835   \n",
       "                                               10        0.708222   \n",
       "                                               20        0.586526   \n",
       "0.03  rating      False                        10        0.213218   \n",
       "                  True                         5         0.522217   \n",
       "                                               10        0.643513   \n",
       "                                               20        0.480604   \n",
       "0.10  rating      False                        10        0.192456   \n",
       "                  True                         5         0.490519   \n",
       "                                               10        0.443158   \n",
       "                                               20        0.410681   \n",
       "\n",
       "                                                         meanOverallDiversity  \\\n",
       "alpha som_variant use_prob_candidate_selection exponent                         \n",
       "0.01  normal      False                        10                    1.322132   \n",
       "                  True                         5                     1.314791   \n",
       "                                               10                    1.301962   \n",
       "                                               20                    1.253461   \n",
       "      topk        False                        10                    1.146293   \n",
       "      rating      False                        10                    1.326315   \n",
       "                  True                         5                     1.277797   \n",
       "                                               10                    1.264255   \n",
       "                                               20                    1.240876   \n",
       "0.03  rating      False                        10                    1.322426   \n",
       "                  True                         5                     1.292314   \n",
       "                                               10                    1.275581   \n",
       "                                               20                    1.246666   \n",
       "0.10  rating      False                        10                    1.321468   \n",
       "                  True                         5                     1.302408   \n",
       "                                               10                    1.291421   \n",
       "                                               20                    1.251601   \n",
       "\n",
       "                                                         meanNeighborDiversity  \\\n",
       "alpha som_variant use_prob_candidate_selection exponent                          \n",
       "0.01  normal      False                        10                     1.243279   \n",
       "                  True                         5                      1.223740   \n",
       "                                               10                     1.202991   \n",
       "                                               20                     1.133690   \n",
       "      topk        False                        10                     1.143876   \n",
       "      rating      False                        10                     1.200821   \n",
       "                  True                         5                      1.160046   \n",
       "                                               10                     1.152093   \n",
       "                                               20                     1.124177   \n",
       "0.03  rating      False                        10                     1.211512   \n",
       "                  True                         5                      1.164219   \n",
       "                                               10                     1.162984   \n",
       "                                               20                     1.128180   \n",
       "0.10  rating      False                        10                     1.225182   \n",
       "                  True                         5                      1.187926   \n",
       "                                               10                     1.185181   \n",
       "                                               20                     1.132241   \n",
       "\n",
       "                                                         neighborOverallRatio  \n",
       "alpha som_variant use_prob_candidate_selection exponent                        \n",
       "0.01  normal      False                        10                    0.940359  \n",
       "                  True                         5                     0.930748  \n",
       "                                               10                    0.923983  \n",
       "                                               20                    0.904448  \n",
       "      topk        False                        10                    0.997892  \n",
       "      rating      False                        10                    0.905382  \n",
       "                  True                         5                     0.907849  \n",
       "                                               10                    0.911282  \n",
       "                                               20                    0.905954  \n",
       "0.03  rating      False                        10                    0.916128  \n",
       "                  True                         5                     0.900879  \n",
       "                                               10                    0.911729  \n",
       "                                               20                    0.904958  \n",
       "0.10  rating      False                        10                    0.927137  \n",
       "                  True                         5                     0.912100  \n",
       "                                               10                    0.917734  \n",
       "                                               20                    0.904634  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanDistN, maxDistN = calculateNeighborsDiversity(resultingIDXDF2, evalProc2.pairwiseSampleDistances, evalProc2.SOM_dim)\n",
    "resultingIDXDF2[\"meanNeighborDiversity\"]  =  meanDistN \n",
    "resultingIDXDF2[\"maxNeighborDiversity\"]  =  maxDistN \n",
    "\n",
    "meanDist, maxDist = calculateOverallDiversity(resultingIDXDF2, evalProc2.pairwiseSampleDistances, evalProc2.SOM_dim)\n",
    "resultingIDXDF2[\"meanOverallDiversity\"]  =  meanDist \n",
    "resultingIDXDF2[\"maxDiversity\"]  =  maxDist \n",
    "\n",
    "resultingIDXDF2[\"nDCG\"] = calculateNDCG(resultingIDXDF2, evalProc2.unbiasedRatings, evalProc2.use_triangular, evalProc2.SOM_dim)\n",
    "resultingIDXDF2[\"neighborOverallRatio\"] = resultingIDXDF2.meanNeighborDiversity / resultingIDXDF2.meanOverallDiversity\n",
    "meanRes2 = resultingIDXDF2.groupby([\"alpha\",\"som_variant\",\"use_prob_candidate_selection\",\"exponent\"])[[\"nDCG\",\"meanOverallDiversity\",\"meanNeighborDiversity\"]].mean()\n",
    "meanRes2[\"neighborOverallRatio\"] = meanRes2.meanNeighborDiversity / meanRes2.meanOverallDiversity\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "meanResReduced2 = meanRes2.loc[idx[:, [\"normal\",\"topk\",\"rating\"],:,:], :]\n",
    "meanResReduced2 = meanResReduced2.drop(meanResReduced2.loc[idx[:, \"topk\",True,:],:].index)\n",
    "meanResReduced2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalProc3 = pickle.load(open(\"pck/evalProcVBSf1_disptopk_triagTrue.pck\", \"rb\"))\n",
    "ratingsDF3 = pickle.load(open(\"pck/ratingsDFVBSf1_disptopk_triagTrue.pck\", \"rb\"))\n",
    "ratingsUnbDF3 = pickle.load(open(\"pck/ratingsUnbDFVBSf1_disptopk_triagTrue.pck\", \"rb\"))\n",
    "resultingIDXDF3 = pickle.load(open(\"pck/resultingIDXDFVBSf1_disptopk_triagTrue.pck\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-03bc8221dfd5>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[\"d_\"+str(i+1)+\"_\"+str(j+1)] = distances[data[\"r\"+str(i+1)],data[\"r\"+str(j+1)]]\n",
      "<ipython-input-8-03bc8221dfd5>:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[\"d_\"+str(i+1)+\"_\"+str(j+1)] = distances[data[\"r\"+str(i+1)],data[\"r\"+str(j+1)]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nDCG</th>\n",
       "      <th>meanOverallDiversity</th>\n",
       "      <th>meanNeighborDiversity</th>\n",
       "      <th>neighborOverallRatio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>som_variant</th>\n",
       "      <th>use_prob_candidate_selection</th>\n",
       "      <th>exponent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">normal</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.199587</td>\n",
       "      <td>1.322132</td>\n",
       "      <td>1.243279</td>\n",
       "      <td>0.940359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.210502</td>\n",
       "      <td>1.314791</td>\n",
       "      <td>1.223740</td>\n",
       "      <td>0.930748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.200902</td>\n",
       "      <td>1.301962</td>\n",
       "      <td>1.202991</td>\n",
       "      <td>0.923983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.264382</td>\n",
       "      <td>1.253461</td>\n",
       "      <td>1.133690</td>\n",
       "      <td>0.904448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topk</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.826294</td>\n",
       "      <td>1.146293</td>\n",
       "      <td>1.143876</td>\n",
       "      <td>0.997892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.162196</td>\n",
       "      <td>1.321710</td>\n",
       "      <td>1.231184</td>\n",
       "      <td>0.931508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.339597</td>\n",
       "      <td>1.305732</td>\n",
       "      <td>1.201860</td>\n",
       "      <td>0.920449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.364079</td>\n",
       "      <td>1.295903</td>\n",
       "      <td>1.192288</td>\n",
       "      <td>0.920044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.415229</td>\n",
       "      <td>1.251498</td>\n",
       "      <td>1.131758</td>\n",
       "      <td>0.904322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.5</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.191998</td>\n",
       "      <td>1.322501</td>\n",
       "      <td>1.235384</td>\n",
       "      <td>0.934127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.233352</td>\n",
       "      <td>1.311036</td>\n",
       "      <td>1.216983</td>\n",
       "      <td>0.928261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.247309</td>\n",
       "      <td>1.299753</td>\n",
       "      <td>1.200809</td>\n",
       "      <td>0.923874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.309236</td>\n",
       "      <td>1.252042</td>\n",
       "      <td>1.132591</td>\n",
       "      <td>0.904595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.9</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.188567</td>\n",
       "      <td>1.322557</td>\n",
       "      <td>1.236021</td>\n",
       "      <td>0.934569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.225542</td>\n",
       "      <td>1.313677</td>\n",
       "      <td>1.222119</td>\n",
       "      <td>0.930304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.221692</td>\n",
       "      <td>1.303009</td>\n",
       "      <td>1.204318</td>\n",
       "      <td>0.924259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.256889</td>\n",
       "      <td>1.254230</td>\n",
       "      <td>1.135764</td>\n",
       "      <td>0.905547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             nDCG  \\\n",
       "alpha som_variant use_prob_candidate_selection exponent             \n",
       "0.2   normal      False                        10        0.199587   \n",
       "                  True                         5         0.210502   \n",
       "                                               10        0.200902   \n",
       "                                               20        0.264382   \n",
       "      topk        False                        10        0.826294   \n",
       "      rating      False                        10        0.162196   \n",
       "                  True                         5         0.339597   \n",
       "                                               10        0.364079   \n",
       "                                               20        0.415229   \n",
       "0.5   rating      False                        10        0.191998   \n",
       "                  True                         5         0.233352   \n",
       "                                               10        0.247309   \n",
       "                                               20        0.309236   \n",
       "0.9   rating      False                        10        0.188567   \n",
       "                  True                         5         0.225542   \n",
       "                                               10        0.221692   \n",
       "                                               20        0.256889   \n",
       "\n",
       "                                                         meanOverallDiversity  \\\n",
       "alpha som_variant use_prob_candidate_selection exponent                         \n",
       "0.2   normal      False                        10                    1.322132   \n",
       "                  True                         5                     1.314791   \n",
       "                                               10                    1.301962   \n",
       "                                               20                    1.253461   \n",
       "      topk        False                        10                    1.146293   \n",
       "      rating      False                        10                    1.321710   \n",
       "                  True                         5                     1.305732   \n",
       "                                               10                    1.295903   \n",
       "                                               20                    1.251498   \n",
       "0.5   rating      False                        10                    1.322501   \n",
       "                  True                         5                     1.311036   \n",
       "                                               10                    1.299753   \n",
       "                                               20                    1.252042   \n",
       "0.9   rating      False                        10                    1.322557   \n",
       "                  True                         5                     1.313677   \n",
       "                                               10                    1.303009   \n",
       "                                               20                    1.254230   \n",
       "\n",
       "                                                         meanNeighborDiversity  \\\n",
       "alpha som_variant use_prob_candidate_selection exponent                          \n",
       "0.2   normal      False                        10                     1.243279   \n",
       "                  True                         5                      1.223740   \n",
       "                                               10                     1.202991   \n",
       "                                               20                     1.133690   \n",
       "      topk        False                        10                     1.143876   \n",
       "      rating      False                        10                     1.231184   \n",
       "                  True                         5                      1.201860   \n",
       "                                               10                     1.192288   \n",
       "                                               20                     1.131758   \n",
       "0.5   rating      False                        10                     1.235384   \n",
       "                  True                         5                      1.216983   \n",
       "                                               10                     1.200809   \n",
       "                                               20                     1.132591   \n",
       "0.9   rating      False                        10                     1.236021   \n",
       "                  True                         5                      1.222119   \n",
       "                                               10                     1.204318   \n",
       "                                               20                     1.135764   \n",
       "\n",
       "                                                         neighborOverallRatio  \n",
       "alpha som_variant use_prob_candidate_selection exponent                        \n",
       "0.2   normal      False                        10                    0.940359  \n",
       "                  True                         5                     0.930748  \n",
       "                                               10                    0.923983  \n",
       "                                               20                    0.904448  \n",
       "      topk        False                        10                    0.997892  \n",
       "      rating      False                        10                    0.931508  \n",
       "                  True                         5                     0.920449  \n",
       "                                               10                    0.920044  \n",
       "                                               20                    0.904322  \n",
       "0.5   rating      False                        10                    0.934127  \n",
       "                  True                         5                     0.928261  \n",
       "                                               10                    0.923874  \n",
       "                                               20                    0.904595  \n",
       "0.9   rating      False                        10                    0.934569  \n",
       "                  True                         5                     0.930304  \n",
       "                                               10                    0.924259  \n",
       "                                               20                    0.905547  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanDistN, maxDistN = calculateNeighborsDiversity(resultingIDXDF3, evalProc3.pairwiseSampleDistances, evalProc3.SOM_dim)\n",
    "resultingIDXDF3[\"meanNeighborDiversity\"]  =  meanDistN \n",
    "resultingIDXDF3[\"maxNeighborDiversity\"]  =  maxDistN \n",
    "\n",
    "meanDist, maxDist = calculateOverallDiversity(resultingIDXDF3, evalProc3.pairwiseSampleDistances, evalProc3.SOM_dim)\n",
    "resultingIDXDF3[\"meanOverallDiversity\"]  =  meanDist \n",
    "resultingIDXDF3[\"maxDiversity\"]  =  maxDist \n",
    "\n",
    "resultingIDXDF3[\"nDCG\"] = calculateNDCG(resultingIDXDF3, evalProc3.unbiasedRatings, evalProc3.use_triangular, evalProc3.SOM_dim)\n",
    "resultingIDXDF3[\"neighborOverallRatio\"] = resultingIDXDF3.meanNeighborDiversity / resultingIDXDF3.meanOverallDiversity\n",
    "meanRes3 = resultingIDXDF3.groupby([\"alpha\",\"som_variant\",\"use_prob_candidate_selection\",\"exponent\"])[[\"nDCG\",\"meanOverallDiversity\",\"meanNeighborDiversity\"]].mean()\n",
    "meanRes3[\"neighborOverallRatio\"] = meanRes3.meanNeighborDiversity / meanRes3.meanOverallDiversity\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "meanResReduced3 = meanRes3.loc[idx[:, [\"normal\",\"topk\",\"rating\"],:,:], :]\n",
    "meanResReduced3 = meanResReduced3.drop(meanResReduced3.loc[idx[:, \"topk\",True,:],:].index)\n",
    "meanResReduced3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float64Index([0.0003, 0.001, 0.003], dtype='float64', name='alpha'),\n",
       " Float64Index([0.01, 0.03, 0.1], dtype='float64', name='alpha'),\n",
       " Float64Index([0.2, 0.5, 0.9], dtype='float64', name='alpha'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(meanResReduced.index.get_level_values(0).unique(),\n",
    " meanResReduced2.index.get_level_values(0).unique(),\n",
    " meanResReduced3.index.get_level_values(0).unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nDCG</th>\n",
       "      <th>meanOverallDiversity</th>\n",
       "      <th>meanNeighborDiversity</th>\n",
       "      <th>neighborOverallRatio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th>som_variant</th>\n",
       "      <th>use_prob_candidate_selection</th>\n",
       "      <th>exponent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.0003</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">normal</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.199587</td>\n",
       "      <td>1.322132</td>\n",
       "      <td>1.243279</td>\n",
       "      <td>0.940359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.210502</td>\n",
       "      <td>1.314791</td>\n",
       "      <td>1.223740</td>\n",
       "      <td>0.930748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.200902</td>\n",
       "      <td>1.301962</td>\n",
       "      <td>1.202991</td>\n",
       "      <td>0.923983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.264382</td>\n",
       "      <td>1.253461</td>\n",
       "      <td>1.133690</td>\n",
       "      <td>0.904448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.533688</td>\n",
       "      <td>1.328966</td>\n",
       "      <td>1.244753</td>\n",
       "      <td>0.936632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.805602</td>\n",
       "      <td>1.234348</td>\n",
       "      <td>1.180323</td>\n",
       "      <td>0.956232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.783595</td>\n",
       "      <td>1.195407</td>\n",
       "      <td>1.128133</td>\n",
       "      <td>0.943723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.741783</td>\n",
       "      <td>1.211393</td>\n",
       "      <td>1.112304</td>\n",
       "      <td>0.918202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topk</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.826294</td>\n",
       "      <td>1.146293</td>\n",
       "      <td>1.143876</td>\n",
       "      <td>0.997892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0010</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.352576</td>\n",
       "      <td>1.330675</td>\n",
       "      <td>1.218020</td>\n",
       "      <td>0.915340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.746656</td>\n",
       "      <td>1.233437</td>\n",
       "      <td>1.164486</td>\n",
       "      <td>0.944099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.778309</td>\n",
       "      <td>1.215835</td>\n",
       "      <td>1.127844</td>\n",
       "      <td>0.927630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.699885</td>\n",
       "      <td>1.224582</td>\n",
       "      <td>1.116802</td>\n",
       "      <td>0.911986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0030</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.280231</td>\n",
       "      <td>1.329422</td>\n",
       "      <td>1.200772</td>\n",
       "      <td>0.903229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.452640</td>\n",
       "      <td>1.255827</td>\n",
       "      <td>1.166896</td>\n",
       "      <td>0.929186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.779164</td>\n",
       "      <td>1.237727</td>\n",
       "      <td>1.137059</td>\n",
       "      <td>0.918667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.621758</td>\n",
       "      <td>1.233709</td>\n",
       "      <td>1.121680</td>\n",
       "      <td>0.909193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.0100</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">normal</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.199587</td>\n",
       "      <td>1.322132</td>\n",
       "      <td>1.243279</td>\n",
       "      <td>0.940359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.210502</td>\n",
       "      <td>1.314791</td>\n",
       "      <td>1.223740</td>\n",
       "      <td>0.930748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.200902</td>\n",
       "      <td>1.301962</td>\n",
       "      <td>1.202991</td>\n",
       "      <td>0.923983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.264382</td>\n",
       "      <td>1.253461</td>\n",
       "      <td>1.133690</td>\n",
       "      <td>0.904448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.260245</td>\n",
       "      <td>1.326315</td>\n",
       "      <td>1.200821</td>\n",
       "      <td>0.905382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.295835</td>\n",
       "      <td>1.277797</td>\n",
       "      <td>1.160046</td>\n",
       "      <td>0.907849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.708222</td>\n",
       "      <td>1.264255</td>\n",
       "      <td>1.152093</td>\n",
       "      <td>0.911282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.586526</td>\n",
       "      <td>1.240876</td>\n",
       "      <td>1.124177</td>\n",
       "      <td>0.905954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topk</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.826294</td>\n",
       "      <td>1.146293</td>\n",
       "      <td>1.143876</td>\n",
       "      <td>0.997892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0300</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.213218</td>\n",
       "      <td>1.322426</td>\n",
       "      <td>1.211512</td>\n",
       "      <td>0.916128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.522217</td>\n",
       "      <td>1.292314</td>\n",
       "      <td>1.164219</td>\n",
       "      <td>0.900879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.643513</td>\n",
       "      <td>1.275581</td>\n",
       "      <td>1.162984</td>\n",
       "      <td>0.911729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.480604</td>\n",
       "      <td>1.246666</td>\n",
       "      <td>1.128180</td>\n",
       "      <td>0.904958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.1000</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.192456</td>\n",
       "      <td>1.321468</td>\n",
       "      <td>1.225182</td>\n",
       "      <td>0.927137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.490519</td>\n",
       "      <td>1.302408</td>\n",
       "      <td>1.187926</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.443158</td>\n",
       "      <td>1.291421</td>\n",
       "      <td>1.185181</td>\n",
       "      <td>0.917734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.410681</td>\n",
       "      <td>1.251601</td>\n",
       "      <td>1.132241</td>\n",
       "      <td>0.904634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.2000</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">normal</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.199587</td>\n",
       "      <td>1.322132</td>\n",
       "      <td>1.243279</td>\n",
       "      <td>0.940359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.210502</td>\n",
       "      <td>1.314791</td>\n",
       "      <td>1.223740</td>\n",
       "      <td>0.930748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.200902</td>\n",
       "      <td>1.301962</td>\n",
       "      <td>1.202991</td>\n",
       "      <td>0.923983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.264382</td>\n",
       "      <td>1.253461</td>\n",
       "      <td>1.133690</td>\n",
       "      <td>0.904448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.162196</td>\n",
       "      <td>1.321710</td>\n",
       "      <td>1.231184</td>\n",
       "      <td>0.931508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.339597</td>\n",
       "      <td>1.305732</td>\n",
       "      <td>1.201860</td>\n",
       "      <td>0.920449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.364079</td>\n",
       "      <td>1.295903</td>\n",
       "      <td>1.192288</td>\n",
       "      <td>0.920044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.415229</td>\n",
       "      <td>1.251498</td>\n",
       "      <td>1.131758</td>\n",
       "      <td>0.904322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topk</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.826294</td>\n",
       "      <td>1.146293</td>\n",
       "      <td>1.143876</td>\n",
       "      <td>0.997892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.5000</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.191998</td>\n",
       "      <td>1.322501</td>\n",
       "      <td>1.235384</td>\n",
       "      <td>0.934127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.233352</td>\n",
       "      <td>1.311036</td>\n",
       "      <td>1.216983</td>\n",
       "      <td>0.928261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.247309</td>\n",
       "      <td>1.299753</td>\n",
       "      <td>1.200809</td>\n",
       "      <td>0.923874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.309236</td>\n",
       "      <td>1.252042</td>\n",
       "      <td>1.132591</td>\n",
       "      <td>0.904595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.9000</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">rating</th>\n",
       "      <th>False</th>\n",
       "      <th>10</th>\n",
       "      <td>0.188567</td>\n",
       "      <td>1.322557</td>\n",
       "      <td>1.236021</td>\n",
       "      <td>0.934569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>5</th>\n",
       "      <td>0.225542</td>\n",
       "      <td>1.313677</td>\n",
       "      <td>1.222119</td>\n",
       "      <td>0.930304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.221692</td>\n",
       "      <td>1.303009</td>\n",
       "      <td>1.204318</td>\n",
       "      <td>0.924259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.256889</td>\n",
       "      <td>1.254230</td>\n",
       "      <td>1.135764</td>\n",
       "      <td>0.905547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              nDCG  \\\n",
       "alpha  som_variant use_prob_candidate_selection exponent             \n",
       "0.0003 normal      False                        10        0.199587   \n",
       "                   True                         5         0.210502   \n",
       "                                                10        0.200902   \n",
       "                                                20        0.264382   \n",
       "       rating      False                        10        0.533688   \n",
       "                   True                         5         0.805602   \n",
       "                                                10        0.783595   \n",
       "                                                20        0.741783   \n",
       "       topk        False                        10        0.826294   \n",
       "0.0010 rating      False                        10        0.352576   \n",
       "                   True                         5         0.746656   \n",
       "                                                10        0.778309   \n",
       "                                                20        0.699885   \n",
       "0.0030 rating      False                        10        0.280231   \n",
       "                   True                         5         0.452640   \n",
       "                                                10        0.779164   \n",
       "                                                20        0.621758   \n",
       "0.0100 normal      False                        10        0.199587   \n",
       "                   True                         5         0.210502   \n",
       "                                                10        0.200902   \n",
       "                                                20        0.264382   \n",
       "       rating      False                        10        0.260245   \n",
       "                   True                         5         0.295835   \n",
       "                                                10        0.708222   \n",
       "                                                20        0.586526   \n",
       "       topk        False                        10        0.826294   \n",
       "0.0300 rating      False                        10        0.213218   \n",
       "                   True                         5         0.522217   \n",
       "                                                10        0.643513   \n",
       "                                                20        0.480604   \n",
       "0.1000 rating      False                        10        0.192456   \n",
       "                   True                         5         0.490519   \n",
       "                                                10        0.443158   \n",
       "                                                20        0.410681   \n",
       "0.2000 normal      False                        10        0.199587   \n",
       "                   True                         5         0.210502   \n",
       "                                                10        0.200902   \n",
       "                                                20        0.264382   \n",
       "       rating      False                        10        0.162196   \n",
       "                   True                         5         0.339597   \n",
       "                                                10        0.364079   \n",
       "                                                20        0.415229   \n",
       "       topk        False                        10        0.826294   \n",
       "0.5000 rating      False                        10        0.191998   \n",
       "                   True                         5         0.233352   \n",
       "                                                10        0.247309   \n",
       "                                                20        0.309236   \n",
       "0.9000 rating      False                        10        0.188567   \n",
       "                   True                         5         0.225542   \n",
       "                                                10        0.221692   \n",
       "                                                20        0.256889   \n",
       "\n",
       "                                                          meanOverallDiversity  \\\n",
       "alpha  som_variant use_prob_candidate_selection exponent                         \n",
       "0.0003 normal      False                        10                    1.322132   \n",
       "                   True                         5                     1.314791   \n",
       "                                                10                    1.301962   \n",
       "                                                20                    1.253461   \n",
       "       rating      False                        10                    1.328966   \n",
       "                   True                         5                     1.234348   \n",
       "                                                10                    1.195407   \n",
       "                                                20                    1.211393   \n",
       "       topk        False                        10                    1.146293   \n",
       "0.0010 rating      False                        10                    1.330675   \n",
       "                   True                         5                     1.233437   \n",
       "                                                10                    1.215835   \n",
       "                                                20                    1.224582   \n",
       "0.0030 rating      False                        10                    1.329422   \n",
       "                   True                         5                     1.255827   \n",
       "                                                10                    1.237727   \n",
       "                                                20                    1.233709   \n",
       "0.0100 normal      False                        10                    1.322132   \n",
       "                   True                         5                     1.314791   \n",
       "                                                10                    1.301962   \n",
       "                                                20                    1.253461   \n",
       "       rating      False                        10                    1.326315   \n",
       "                   True                         5                     1.277797   \n",
       "                                                10                    1.264255   \n",
       "                                                20                    1.240876   \n",
       "       topk        False                        10                    1.146293   \n",
       "0.0300 rating      False                        10                    1.322426   \n",
       "                   True                         5                     1.292314   \n",
       "                                                10                    1.275581   \n",
       "                                                20                    1.246666   \n",
       "0.1000 rating      False                        10                    1.321468   \n",
       "                   True                         5                     1.302408   \n",
       "                                                10                    1.291421   \n",
       "                                                20                    1.251601   \n",
       "0.2000 normal      False                        10                    1.322132   \n",
       "                   True                         5                     1.314791   \n",
       "                                                10                    1.301962   \n",
       "                                                20                    1.253461   \n",
       "       rating      False                        10                    1.321710   \n",
       "                   True                         5                     1.305732   \n",
       "                                                10                    1.295903   \n",
       "                                                20                    1.251498   \n",
       "       topk        False                        10                    1.146293   \n",
       "0.5000 rating      False                        10                    1.322501   \n",
       "                   True                         5                     1.311036   \n",
       "                                                10                    1.299753   \n",
       "                                                20                    1.252042   \n",
       "0.9000 rating      False                        10                    1.322557   \n",
       "                   True                         5                     1.313677   \n",
       "                                                10                    1.303009   \n",
       "                                                20                    1.254230   \n",
       "\n",
       "                                                          meanNeighborDiversity  \\\n",
       "alpha  som_variant use_prob_candidate_selection exponent                          \n",
       "0.0003 normal      False                        10                     1.243279   \n",
       "                   True                         5                      1.223740   \n",
       "                                                10                     1.202991   \n",
       "                                                20                     1.133690   \n",
       "       rating      False                        10                     1.244753   \n",
       "                   True                         5                      1.180323   \n",
       "                                                10                     1.128133   \n",
       "                                                20                     1.112304   \n",
       "       topk        False                        10                     1.143876   \n",
       "0.0010 rating      False                        10                     1.218020   \n",
       "                   True                         5                      1.164486   \n",
       "                                                10                     1.127844   \n",
       "                                                20                     1.116802   \n",
       "0.0030 rating      False                        10                     1.200772   \n",
       "                   True                         5                      1.166896   \n",
       "                                                10                     1.137059   \n",
       "                                                20                     1.121680   \n",
       "0.0100 normal      False                        10                     1.243279   \n",
       "                   True                         5                      1.223740   \n",
       "                                                10                     1.202991   \n",
       "                                                20                     1.133690   \n",
       "       rating      False                        10                     1.200821   \n",
       "                   True                         5                      1.160046   \n",
       "                                                10                     1.152093   \n",
       "                                                20                     1.124177   \n",
       "       topk        False                        10                     1.143876   \n",
       "0.0300 rating      False                        10                     1.211512   \n",
       "                   True                         5                      1.164219   \n",
       "                                                10                     1.162984   \n",
       "                                                20                     1.128180   \n",
       "0.1000 rating      False                        10                     1.225182   \n",
       "                   True                         5                      1.187926   \n",
       "                                                10                     1.185181   \n",
       "                                                20                     1.132241   \n",
       "0.2000 normal      False                        10                     1.243279   \n",
       "                   True                         5                      1.223740   \n",
       "                                                10                     1.202991   \n",
       "                                                20                     1.133690   \n",
       "       rating      False                        10                     1.231184   \n",
       "                   True                         5                      1.201860   \n",
       "                                                10                     1.192288   \n",
       "                                                20                     1.131758   \n",
       "       topk        False                        10                     1.143876   \n",
       "0.5000 rating      False                        10                     1.235384   \n",
       "                   True                         5                      1.216983   \n",
       "                                                10                     1.200809   \n",
       "                                                20                     1.132591   \n",
       "0.9000 rating      False                        10                     1.236021   \n",
       "                   True                         5                      1.222119   \n",
       "                                                10                     1.204318   \n",
       "                                                20                     1.135764   \n",
       "\n",
       "                                                          neighborOverallRatio  \n",
       "alpha  som_variant use_prob_candidate_selection exponent                        \n",
       "0.0003 normal      False                        10                    0.940359  \n",
       "                   True                         5                     0.930748  \n",
       "                                                10                    0.923983  \n",
       "                                                20                    0.904448  \n",
       "       rating      False                        10                    0.936632  \n",
       "                   True                         5                     0.956232  \n",
       "                                                10                    0.943723  \n",
       "                                                20                    0.918202  \n",
       "       topk        False                        10                    0.997892  \n",
       "0.0010 rating      False                        10                    0.915340  \n",
       "                   True                         5                     0.944099  \n",
       "                                                10                    0.927630  \n",
       "                                                20                    0.911986  \n",
       "0.0030 rating      False                        10                    0.903229  \n",
       "                   True                         5                     0.929186  \n",
       "                                                10                    0.918667  \n",
       "                                                20                    0.909193  \n",
       "0.0100 normal      False                        10                    0.940359  \n",
       "                   True                         5                     0.930748  \n",
       "                                                10                    0.923983  \n",
       "                                                20                    0.904448  \n",
       "       rating      False                        10                    0.905382  \n",
       "                   True                         5                     0.907849  \n",
       "                                                10                    0.911282  \n",
       "                                                20                    0.905954  \n",
       "       topk        False                        10                    0.997892  \n",
       "0.0300 rating      False                        10                    0.916128  \n",
       "                   True                         5                     0.900879  \n",
       "                                                10                    0.911729  \n",
       "                                                20                    0.904958  \n",
       "0.1000 rating      False                        10                    0.927137  \n",
       "                   True                         5                     0.912100  \n",
       "                                                10                    0.917734  \n",
       "                                                20                    0.904634  \n",
       "0.2000 normal      False                        10                    0.940359  \n",
       "                   True                         5                     0.930748  \n",
       "                                                10                    0.923983  \n",
       "                                                20                    0.904448  \n",
       "       rating      False                        10                    0.931508  \n",
       "                   True                         5                     0.920449  \n",
       "                                                10                    0.920044  \n",
       "                                                20                    0.904322  \n",
       "       topk        False                        10                    0.997892  \n",
       "0.5000 rating      False                        10                    0.934127  \n",
       "                   True                         5                     0.928261  \n",
       "                                                10                    0.923874  \n",
       "                                                20                    0.904595  \n",
       "0.9000 rating      False                        10                    0.934569  \n",
       "                   True                         5                     0.930304  \n",
       "                                                10                    0.924259  \n",
       "                                                20                    0.905547  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanResReducedMerged = meanResReduced.append(meanResReduced2).append(meanResReduced3)\n",
    "meanResReducedMerged.sort_index(inplace=True)\n",
    "meanResReducedMerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanResReducedMerged = meanResReducedMerged.drop(meanResReducedMerged.loc[idx[:,:,:, 5],:].index)\n",
    "meanResReducedMerged = meanResReducedMerged.drop(meanResReducedMerged.loc[idx[[0.01,0.2], [\"normal\",\"topk\"],:,:],:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Index([0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.2, 0.5, 0.9], dtype='float64', name='alpha')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanResReducedMerged.index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEYCAYAAAAXsVIGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABYFUlEQVR4nO2dd3hU1daH35VGCEnoTVEponQDcvHaKCJWQMWKgHAVvdhQFEW8goqioGLnqtgoKmIHCyqX5tWrAgI2LKAfKr3XJCQk6/vjnBkmZZIzySSZSdb7POfJmd3OmgTmN3vvtdcSVcUwDMMwIoWYijbAMAzDMAIxYTIMwzAiChMmwzAMI6IwYTIMwzAiChMmwzAMI6KIq2gDyoN69epp06ZNK9oMwzCqCN988802Va1f2nGOO6m17t2133P7//vpr09U9azSPreiqRLC1LRpU5YtW1bRZhiGUUUQkT/CMc7eXfu5b8atntsP7HxzvXA8t6KpEsJkGIYRrShS0SaUOyZMhmEYEYoCVTEGggmTYRhGBJNb0QZUACZMhmEYkYrajMkwQmLPvgwyDmQDUL1aPKnJ1SvYIsOoXKh7VTVMmIwSk3Egm64DJwHw2Su3mjAZRhlgMyYjatmzN4PMjCz/68TqCaSmmFBUBHvSM8nIPuh/XT0+jtSkxAq0yIhmTJiMqCUzI4ueZ43zv57/8diwC1Pg0h3Azt3phd5X9WW9jOyDdLn7Gf/rJfdeS2oF2mNEN1VQl0yYDO8ELt3l57zrD30Q27KeYYQPmzEZEc2evRlkZjrLdYmJCQD+5bsdO/flaRv42pb1yp7A5bvt+9Lz1AW+tmU9IxQUyDVhMiKZzMwsep57HwDzPxwDSp7lu0Au7v+o/74slvWMvORfvgvk7Ien+e9tWc8IFTvHZBhFUL1aPJ+9cihu187d6f4lvNmTr6V2zSR/O8MwwoCdYwovIvIS0BvYoqrtCqk/D7gP5wvBQeBmVf1cRNKAZ4BUIAcYr6qz3D5TgW7AbneYIaq6sqzeQ0UTuHQHeZfnduzcR+1aNZg3dwwJCXFs2bI7zyzpzZm3UKd2MuAs5YWD1OTqQfeOatdMomFdmwsYRjixc0zhZyrwNDA9SP18YI6qqoh0AN4AWgHpwBWqulpEDgO+EZFPVHWX2+82VX2rDO2OGAKX7vJz8cDH/PfzPxzjFyEfdWon06BBzTK1zzhE9fg4ltx7LeDsKQUu3829bTB1k5P87QwjFGzGFEZU9TMRaVpEfeBufQ3cLwaq+mtAmw0isgWoD+wqG0tLzp70TPYfyEZRqsXFsf9AFq9+tZKj6taiV7uWJCXEk5Odk8fFujK5Ugcu7VX15bvUpMSge0d1k5NoWDM5SK1hFE0V1KWK3WMSkQuAB4EGwLmF1HcBEoDfAorHi8hYnBnXHap6IJw27UnPJD3rkJAkJcQH9aJKzzrICWOeBeCD2wZRO7k6L37m5H0aN3sB/+rTnV7HHk23Kw65WH82o/K4Uhe1tGcYRniwGVM5o6rvAu+KSFec/abTfXUi0hiYAQxWVZ9jymhgE45YTQFGAYW6pYnINcA1AEceeaRnm9KzsvnbqEPeVUsnXuvZvTcwa8rB3Fzunb2A7rc28/zs/CQmJjjedy47du7zL+G9+cqIQ3tIruv4/I/HHuobpn0lI3QCl/V8rw2jpFRBXYoMrzx32a+5iNRT1W0ikgp8CPxLVb8KaLfRvT0gIi8DI4sYcwqOeNG5c+ew/G2d2dRBVBVF2bEvw1+XnpVNHaqzaNTVJMbHkZl9kPjYGP7auDPPGKFESEhNqR7UzbtO7WQa1K9ZoL1R8RS1rGcYoWD5mMoZETka+M11fugEVAO2i0gC8C4wPb+Tg4g0VtWNIiLA+cAP4bAlcPlux96MPHWBr1XxL93l55InXvfff3DbIHo/NIMv7r2aAbe+mKfdeTcEREioRMt6hmGUDVVQl8rUXXwm0B2oJyLrgLuBeABVfRa4ELhCRLKBDOBSV6QuAboCdUVkiDuczy38VRGpj7NqthIYFg5b8y/fBXLm/VP9919PCO1xjn6Gj8ClPd/ynWEYlRubMYURVe1fTP1EYGIh5a8ArwTpc1p4rCsZ1eLiWHL/tagqObm57NyfwbkPzQDgjZsu4/DaqYhAfGwMH9w2kMT4OF6ddFWeWdPsp0t+ELWopT3DMCofqpBjwlQ1SUqIZ+lEZ7N6x96MPLOkT+4aQh1XDOJjY6ibksSe/ZlkZGVTNyUpzxgAO3xx0QR+27KDxnVS8jzLDqIahhEKNmOqoqQmJQb1vKuTUp1GtfKKS2qNRFJrJLJpV97AqSLQb/KrAMSIMPLsUzmqXauyMdowjCpBFdQlE6ZwIiJc/vfjaFqvNr3TWpGUEM/+/WE9ZmUYRhXDZkxGSCQlxPH1fcPIyc0lPjaGuNhYxvXrladN7sFcPptxKPBpVY+QYBhGaFRBXTJhyk/gfpPvdTBSkxJBISMrGxTiY2IKtrHoCIZhlBA7x2QARe83Fdre3W8yDMMoC6JZl0QkGQrERi2Wgl/xDcMwjIghV71fkYKItBeRFcCPwCoR+UZECqQ/CoYJk2EYRgSjIVwRxHPALap6lKoeCdyKGyLOC7aUZxiGEaFo9GawraGqC30vVHWRiNTw2tmEyTAMI4KJTl3idxEZg5MhAmAg8LvXzraUZxiGEcH4Zk1ergjiSpwEr++4V323zBM2YzIMw4hgIsmpwSuquhMYXtL+JkyGYRgRSgQ6NRSJiDyuqjeLyPsUYrqq9vUyjgmTYRhGBBNlMybfntIjpRnEhMkwDCOCiSZdUtVv3Ns0VX0isE5EbgIWexnHnB/Kmd37M9m1L6P4hoZhGESt88PgQsqGeO1sM6YwsS/jADUSE/Jkrc1ftnt/Js9/+DULVqxm+h39qVfTs1u/YRhVkCjcY+oPXA40E5E5AVUpwA6v49iMKQxs3rmXqx5+k/Xb9qDu15b8ZT5Revq9L1j1xxaumDCTbbv3V7DlhmFENAqq6vmKAP4HTAJ+dn/6rluBM70OYsJUSrbs3Mel973C1z//Sb+7p7F+2548ZRffO4Otu/b7RcmHiZNhGF6IppBEqvqHqi5S1RNVdXHAtVxVD3odx4SplMTFxlDfXZLbsmsf5415mfPGvMzaTTuJi41hwtVnM33esjyi5KMocdq5N52/tu4iJye3zN+DYRiRS7j3mETkLBH5RUTWiMgdhdQfJSLzReQ7EVkkIk0C6h4SkR9F5CcReVIC9y7yjvF3EVkqIvtEJEtEckRkj9f3bMJUSuqkJvHciIv427HO3277nnQ27tgLQJdjm9C+WWPm/G9V0P6/rtvG2k07yD6Y4y/buTedm5+eTd87X+aPLTtNnAyjChNOYRKRWGAycDbQBugvIm3yNXsEmK6qHYBxwINu35OAk4EOQDvgb0C3II96GugPrAaqA0Pd53qiTIVJRF4SkS0i8kOQ+vNcVV4pIstE5JSAusEistq9BgeUHy8i37tqH1Sxy5M6qUk8MqxPgfKRl3Sndkp13hg7iCMb1CpQHxcbw9RRl9K2aSPi42KBQ6L02Xf/x659GVw4drqJk2FUUUJZxvM4YeoCrFHV31U1C3gdOC9fmzbAAvd+YUC9AolAAlANiAc2B7VddQ0Qq6o5qvoycJY3E8t+xjSVoo2ZDxynqmk4cZReABCROsDdwAk4v8i7RaS22+cZ4GqgpXt5frNlxeadexk88fUC5cMef4f123bTsHZyAXHyidLxLZv4060HipIPEyfDqNqEmI+pnvsl33ddk2+4w4G/Al6vc8sC+Rbo595fAKSISF1V/RJHqDa61yeq+lMQs9NFJAFY6S7/jSAEvSlTYVLVzyjCRVBV9+khV5IaHBL9M4F5qrrDjbk0DzhLRBoDqar6ldtvOnB+mb0BD/gcHdZu2gnA0YfXo0PzRk7drn30u3s6G7bvoVGdFL84eRUlH9EkTrv3ZZCZlV3RZhhGpSHEpbxtqto54PKcAymAkUA3N9FfN2A9kCMiRwOtgSY4YnaaiJwaZIxBOPpyA7AfOIJDYlcsFb7HJCIXiMjPwIccij4bTNUPd+/zlxc27jW+bw1bt24Nv+Eugc4PrY6oz+t3DWDqqMv8e051UqpTLd45LtaoTgpv3j2IV++8PI8ouQYTFxsb9DkxIsSIQIUvXAZn194MHpj2H35Ys9HEyTDCRJiX8tbjiISPJm7ZoeepblDVfqraEfiXW7YLZ/b0lTuh2AfMBU4s1GbHOy9TVfeo6r3AfcBl3kyMAGFS1XdVtRXOzOe+MI47xfetoX79+uEatgA+54f+p6Xxyp2XU69mDeqkJPHcLXnLfDSsnULa0YflFSWgdnJ1HrmuD6d1PLrgM1KSeHvcFRzRoBaxMRX+JyuUXXszGPfix7w1fyWD7nnFxMkwwkAosyWPXnlLgZYi0sxdarsMCDwIi4jUExHfB81o4CX3/k+cmVSciMTjzKZ+ytf3CBGZIiIfiMhQEakhIpOAX4AGXt93xHzKuct+zUWkHsFVfb17n7+8QqmTmsSdl/fMI0B1UgqW+fDNoPJTmDhFkyjN/szxcck6mGPiZBhhIpwzJvcs0Q3AJzii8oaq/igi40TEF/m7O/CLiPwKNATGu+VvAb8B3+PsQ32rqu/ne8R0YAPwFNAWWAYcBnRQ1Zu8vucK/aQTkaN9XnUi0gnH02M7zi/tDBGp7To9nIGz0bYR2OP6yAtwBTC7gszPQ0pSNU9lxREoTtEoSj5MnAwjPIT7HJOqfqSqx6hqC1Ud75aNVdU57v1bqtrSbTNUVQ+45Tmq+k9Vba2qbVT1lkKGr6Oq96jqJ6o6AicU0QBV3RTKey7TWHkiMhNHfeuJyDocT7t4AFV9FrgQuEJEsoEM4FLXqWGHiNyHM+0EGKeqPieK63C8/arjrHHOLcv3UBH4xCkjM4uGdVIiVpSyD+bw2crfCoiSj6yDOQyb+Ab/fa7E+cJCYn/GAWpUD/3LgGFEMpEQ0SEU3MmEbzd8O1DTNwEJ+BwvkjIVJlXtX0z9RGBikLqXOLS2GVi+DOdwV6WmdnJ1aidXr2gziiQ+LpZuHVvwjz4n8PL7Xxeor5GYwCv3DiIuLrhTR7jYvS+DN+ctp2+3DjSok1LmzzOM8iIyQuB5pibwDXndtJa7PxVo7mUQiy5ulIqaydW58WLHYzRQnGokJvDGA0No0aSe//BwWbF7XwbPvPFfXnzvS17/eDmvPTjExMmoFCjRJUyq2jQc40TmGpERVfjE6R99TgAqTpQA/ti4g8tHT2WLGxbKMKKdMLuLRwU2YzLCgk+cqifEc+7JbSpElHz4xMlmTkZlIJpmTOHCZkxG2KiZXJ2rz/s7LQ4ve1FKz8zinfkrC4iSjz827mDwmBlkZGaVqR2GUaaEEI4otxIJmAmTEVZSk6sTH1/2zg5JiQn06daeY5sWfmYvPi6Ge689J09GYcOINkJZxoskXRKRSSLStqT9TZiMqKVerWSmjhtUQJzi42KYOm4QHVoeTmK+CBuGEXVEozI5h3eniMjXIjJMRGqG0tmEyYhq8ouTiZJR2Qj3AdvyQFVfUNWTcYIgNAW+E5HXRKSHl/4mTEbU4xOndkc3NlEyKh3ROWHyJyVs5V7bcMIY3SIiBXME5cO88oxKQb1aybwyfgixMWKiZFQqImkm5BUReQzojZNw8AFVXeJWTRSRX4rrb8JkVBpqVE+oaBMMI+xEoS4BfAfcpar7C6nrUlxnW8ozDMOIUHyRH6JtjwkYmF+URGQ+gKruLq6zzZgMwzAimMjSm6IRkUQgCSdwd2Aw11SCJHUtDBMmwzCMSCXyZkLF8U/gZpwcTMsDyvcAT3sdxITJMAwjkokiYVLVJ4AnRORGVX2qpOOYMBmGYUQwUaRLiMhpqroAWC8i/fLXq+o7XsYxYTIMw4hQlKiLgdcNx0W8TyF1CpgwGYZhRDvRtMekqne7P/9RmnHMXdwwqjjbduxlx67CjpsYRskQkZtEJFUcXhCR5SJyhtf+JkyGUYXZtmMvV458iWvvnG7iFKFE6TmmK1V1D3AGUBcYBEzw2tmEyTCqKD5RWrN2C9//vM7EKRIJQZQiTJh855fOAaar6o8BZcVSZsIkIi+JyBYR+SFI/QAR+U5EvheR/4nIcW75sSKyMuDaIyI3u3X3iMj6gLpzysp+w6jMBIqSDxOnyCRKg7h+IyKf4gjTJyKSAuR67VyWM6apwFlF1P8f0E1V2wP3AVMAVPUXVU1T1TTgeCAdeDeg32O+elX9qEwsN4xKTGGi5MPEKbKIxpBE4mTnHAvcAfxNVdOBBMCzQ0SZeeWp6mci0rSI+v8FvPwKaFJIs57Ab6r6R5jNM4wqy8GcXNIzgqec37c/k9xcz19uDSMPqqoi8pE76fCVbQe2ex0jUvaYrgLmFlJ+GTAzX9kN7hLgS24spkIRkWtEZJmILNu6dWs4bTWMqKZR/Zq88uQ1HNawVoG6ZkfUY9pjQ6lXJ6X8DTMKJdpmTC7LReRvJe1c4cLkZjS8ChiVrzwB6Au8GVD8DNACSAM2ApOCjauqU1S1s6p2rl+/frjNNoyopjBxMlGKTKJUmE4AvhKR3wJ8Cb7z2rnYpTwRqetOw8KOiHQAXgDOLuQZZwPLVXWzryDwXkSeBz4oC7sMoyrgE6eBw6dQLSHORClCiSy98cyZpensZY/pKxFZCbwMzFUNjy6LyJE44SkGqeqvhTTpT75lPBFprKob3ZcXAIV6/BmG4Q2fOMXFxpgoRSAROBPyhKr+ISKnAC1V9WURqQ8ke+3vRZiOAU4HrgSeFJE3gKlBxMSPiMwEuuPk5VgH3A3Eu0Y/i+O1URf4t+PEwUFV7ez2rQH0wgmhHshDIpKG8yVibSH1hmGESKP6NSvaBKMIolGYRORuoDNwLM6kJh54BTjZS/9ihcmdIc0D5rn7Qa8A14nIt8AdqvplkH79ixl3KDA0SN1+HNHKXz6oOHsNwzCMCucCoCNuTiZV3eCeZfKEpz0mYCBOSInNwI3AHBwHhDeBZiGbbBiGYXgiGmdMQJbrNq7gXwXzjJelvC+BGcD5qrouoHyZiDwbysMMw6ia7N2XgSqkplSvaFOijigVpjdE5DmglohcjbMV9LzXzl7cxe9S1fsCRUlELgZQ1YmhWmsYRtVi774M3vpwGRf982k2b9tT0eZEHdEYkkhVHwHeAt7G2WcaG0pGWy/CdEchZaO9PsAwjKqLT5QefnYu6zbuZNDw50ycQiI6o7iKyC3AKlW9TVVHquq8UPoHXcoTkbNxAvAdLiJPBlSlAgdLZK1hGFWGQFHy4ROnGU/+k4b1UivQuugg0mZCIZACfCoiO4BZwJuB51CLo6gZ0wZgGZAJfBNwzaGUh6cMw6jcFCZKPmzmFALROWFCVe9V1bbA9UBjYLGI/Mdr/6AzJlX9FvhWRF5VVZshGYbhGVX4YP63Qes3bN7FL79tpGZKdRKrxZejZVFIBAlOCdgCbMIJ4NrAa6egMyb3IC3ACjfWke8KKeaRYRhVj9SU6kyZOITWLQ8rUBcTIzx2z+Uc36GpiZIHotH5QUSuE5FFwHycM6lXq2oHr/2Lche/yf3Zu+TmGYZRValbO5kpE4dwzaip/LR6A3BIlE7qfDQ1qlerYAujg0haoguBI4CbVXVlSToHnTEFxKTbBvzl5kSqBhyHs/9kGIZRJD5xat3yMBOlEhLuPSYROUtEfhGRNSJSwOtaRI4SkfnuCtkiEWkSUHekiHwqIj+JyKr8OfdExOfR8jDwp4jUCby8vmcvB2w/A051cx99CiwFLgUGeH2IYRhVF584/fr7Jjq0OcJEKQR8GWzDhYjEApNxYpGuA5aKyBxVXRXQ7BFguqpOE5HTgAdxIv8ATAfGq+o8EUmmYLr013BW2b5xzZd8b6e5Fzu9CJOoarqIXAX8W1UfcqONG4ZheKJu7WQ6d2hKfHyZJc02vNEFWKOqvwOIyOvAeUCgMLUBbnHvFwLvuW3bAHG+M0mqui//4Kra2/1ZqlB1Xg7YioiciDND+tAtiy3NQ43QycnJqWgTDKNUmCiVgPC7ix8O/BXwep1bFsi3QD/3/gIgxY2ZegywS0TeEZEVIvKwOwPLg4jEiUgfEbnNvc4VkZD++F6E6SacSA/vquqPItIcR0WNcmTP3kx27tpf0WYYhlHOhOiVV09ElgVc15TgkSOBbiKyAugGrAdycFbYTnXr/4azLDcksKOIHA78CNwKHIYjercDP4pIQRfNIBSpYq4a9lXVvr4ydwo43OsDjNKTkZnFq7M+p02rw+l+ahtiYrx8nzAMo1IQ2h7TNl9euyCsx/GY89HELTv0ONUNuDMmdx/pQlXd5ebVWxmwDPge8HfgxYDu44FnVPXxwDFFZDjOXtVgL2+iSGFS1Rw3C6FRgezdm8HLMxZRu1YNOrQ7ElXNM21PTEwoUdTmjMwsqicmhM/QMOJLlOwmkTSMKkuY3cWXAi1FpBmOIF0GXB7YQETqATtUNRdnteylgL61RKS+qm4FTsOJDhTI31V1SMH3oE+KyC9ejfTy1XuFiMwRkUEi0s93eX2AUXLS0w+wcdNO7hg7k6ysg2zespuHHp3Djh37efaF/3Bm7/H0PPs+MjOzQh571679/O/LX0rUtzzYtWs/u3ans39/JunpByraHMOoMMJ5wNaN4nMD8AnwE/CGu0UzTkR8K2PdgV9E5FegIc4sCFXNwVnGmy8i3+N43OVPZZFRxOPTPZgIePPKS8QJJ3FaQJkC73h9iBE6e/dm8MwL85j5xhcczDnkkTl33rcs/uJnrrqiO+/MGsmwGz2nOPGjqqz6eR2j7nqVue/dSWKEzZoOHsxh8ec/0bxpAz6d/y2XX3oKSUnmYmxUUcJ8wFZVPwI+ylc2NuD+LZyUFYX1nQcUFcGhZpCJi+AEAPeEl9Tq//A6mBE+FLigbxe+++FPvv3+jzx1f+/cglNObMUn875l+469oY2ryq5d+7nvwXc4cOAgTz0zl5Ej+kZUArc9ezOY9spiHhzXn1dn/pd163Yw7u5LSE1JqmjTDKNcibRQQx5YDPQJUveZ10G8pFY/BngGaKiq7USkA45DxP1eH2KETmpKdVJTqvP0o/9g9gfLeOSJDwB46P7L2b/vADeMeImtIUZn3rV7Pz/8+BfjJ77DuvU7AHh3zlLWb9jJmNEXUrdOMikVKFBZWdns3ZvJos9+ZOL9lzNx0mwOHsxl/sLv6X1OJzp3akGtWiFlaDaM6CeKYhKFayLjZY/peZwNsGz3wd/hbJgViYi8JCJbROSHIPUDAoLC/k9EjguoW+uWrxSRZQHldURknoisdn/W9mB/VFOrZg36ntuZww+rzYl/O5rcHOXeB94KWZQyMrP4ZvnvjLhtml+UfCxZtoarr3uOvfsyOHAgO5zme2bPnnQWLPqRLVt3s3XbHgZd+TRLlq7x14+4bRrXDn+eX37dwJ49npeqDSO6UcgN4aoseBGmJFVdkq/MSxqMqcBZRdT/H9BNVdsD9wFT8tX3UNW0fK6PdwDzVbUlTtTawrLrVjpq1Uzirtv7cf2ws3jqmY9LNEb1xAROPulYPpo9mn7nd/GXJ1aLZ/Rt5/PGKzfTqGEtqlVgtOfWrQ4nNjaWmJgYYmIKeuPFiCAxkjfISZiIVCcQw4jK8OKlxIvzwzYRaYH7tkXkImBj0V1AVT/LH+AvX/3/Al5+heNPXxzn4XiMAEwDFgGjPPSLakSENq2bkJOTy/QXry9Q79V5IbFaAonVEhh5Ux/Wr9/B10vXMGL4uVx0wQkkJFRs+oHU1CRSU5PYtXs/HdofxdTnr+eRx+bw1ZLVADz56D/omNaMWjXDv5S3e086e/ak0+TwuuaebkQclUhvPONFmK7Hmc20EpH1ODOdcAdwvQoITHWpOGl5FXhOVX2zqYYBUc834bgyFop74vkagCOPPDLM5pY/dWonh22slJTq3HXHhQy97lnOPiOtwkUpkFo1a3DsMY25ddQMRt16HpcNeowe3dpxfKcWZeagsWHDDkaMms7MqcOpHcbfs2GEgyjaYqK4o0Sq6smb24sw/aGqp4tIDSBGVUNzAysGEemBI0yBB3lPUdX1ItIAmCciP6tqHo8OVVVXuArFFbMpAJ07d46iP235ULduMtNfuJ6aNSPP0612rWSGX3c21arFMejyblx2ycllJkq7d6dz9/1vsn7DDhYs/oE+53YmwWK6GZFEdH16BfPIgxCOGXn5H/h/IvIxMAtY4GVQr7gefi8AZ6vqdl+5qq53f24RkXdxIuJ+BmwWkcaqulFEGuOk7TVKQEpydRLi4yI2vFGzpvUB+OfQXpTF6lp6+gF270nnoUmz+ekXJyLLxElzyMzM5pwzO5KamkRsbGT+boyqQ7RtHYXLK8+LMLXCya9xPfCiiHwAvK6qn5fmwSJyJI56DlLVXwPK/TMz9/4MYJxbPQcn1tIE9+fs0thQ1alIR4fiqFkGe0k+DhzI5j8Lv+fu+97Ic3g5IzOLCZNmM/21z3jlpRupmZpEQoLNnoyKJcqW8m4pql5VH/UyTrFfCVU1XVXfUNV+QEec07uLPRg4E/gSOFZE1onIVSIyTESGuU3G4uSC/3c+t/CGwOci8i2wBPhQVX2uaBOAXiKyGjjdfW0YIVGtWjxdT27Nv58YSpPD6+apO71He15+7jpqJFUzUTKM0Ekp5vKEp/95ItINJ2vtWThB+y4pro+q9i+mfigwtJDy33HStxfWZzvQ04PJhlEktWrV4O9dWvLqyzdyyaDH2Lx5N1cN7sHQIaeRnBw5UTACSc84QPXEBPMcrEqEkDI9ElDVe8MxTrEzJhFZC9wM/Bdor6qXqOrb4Xi4YVQkIkKtmkncedsFpCQnMujyrhErSlnZB/n8y1/YtdsOF1c1ovEYk4gkisj1IvJvN9jCSyLyUvE9Hbzs7nZQ1QtUdaaqWqY6o1IRExNDx+Oa8fADgyIqXmB+9uzJYMz9b7D481UcPGjZjKsU0ahMMANoBJyJs/XTBPDs0R10KU9EblfVh4D7C1s6UFVLFmhUCmrXqkHH45pGbOrvPXsyeGHaAvbvP8Ckpz7klBOPpVatZOLMa7BKEE1LeQEcraoXi8h5qjpNRF7DWXXzRFH/E39yf35TKvMMIwqIxLQae/dmsG3HXsZNeJuly38HYOeu/fQb8Cgjh/fh1JNaUduC2hbKpm17iIuNoV6UH5hWDiXNjDJ8QTd3iUg7nIAIDbx2DipMqvq++3NaqcwzDCNksrIOkpV9kJtHTee3/9ucp27Hzv2Mm/A299x5ET27t4vYLMQVxaZte+g/eirVE+OZPm5QpRCnKGSKG2T7LpxjPsnAGK+di1wLEJHBIrJcRPa71zIRuaJ09hqGURwJCXHUrZPC1GevZdL4gaSmHtr/6tfnb8x95w569WhvopQPnyit27KL1X9u5YqxM9i2c19Fm1U6omyPSURigD2qulNVP1PV5qraQFWf8zpGUGESkcE43ni3AocBhwO3AzeJyKDSmW4Yhhdq16rB6T3aM+7OiwHo0O5IRg7vTf16qRF9QLoiCBQlH1EvTq67uNcrElDVXBytKDFFzZiuBS5Q1YWqultVd6nqAuBCnCgQhmGUA7GxMRzfsTktWzTintEXkZoaWnzDA1kVk2OrPClMlHxEuzhF2YTJx39EZKSIHOHm0asjInW8di7K+SFVVdfmL1TVtSLiOXe7YRilp3atGkx58mqqhRgJPiMzix279lO/bkqlDk4bEyPEx8cGrY+Pi3VyeUUjEaY4HrnU/Rk4iVGguZfORc2YMkpYZxhGGZCaUj3PXpMX9uzN4LJrnmbv3sr9X7ZBnRReuf8KmuULMQXQpnkjXrpnAHXLMP5iWRKNMyZVbVbI5UmUoGhhau2mPs9/fY8T2NUwjHIk1D2l/ekHePKFT9mxaz9TZ/2XjEqepbcwcaoUohRle0wAIpIkIneJyBT3dUsR6e21f1Fz+9alts4wjHInO/sge/ZlMv2Nz5n98XIApr/xOck1Erm4TxdSU5Mq7eFcnzgNvGs61avFR7Uo+YkgwQmBl3HOwJ7kvl4PvAl84KVzUeeY/ii1aYZhlCvpGQf4afUGrr9jGnv3ZfrLD+bk8uQLnzLjzS944dGrOOqIepXW1dwnTrGxMdEvSkSrLtFCVS8Vkf7gZKmQEKIPV86vTYZRRUmqXo0WRzXk2Yf+QYumeQ/atz32cJ5/9CoaN6xdaUXJR4M6KZVClCA6l/KALBGpjqurItICOOC1swmTYVQyatVMIq3dUUx/ahjtWzcB4KS/teT5SVfRuuVh1AzRgcKoQKLwHJPLPcDHwBEi8iownxDONlVe/9FCyM7OZt26dWRmZhbf2DDKmMTERJo0aUJ8fNkclK1VM4l7Rvbj4qufYswt51MzxPNPRmSgUbiYp6qfisg3wN8BAW5S1W1e+xcVXfx7Cl/eFOe52iFUYyuadevWkZKSQtOmTS3ZmlGhqCrbt29n3bp1NGvWrMyec1ij2jw09jLqWLDX6CX6dAkReR94DZhTknRJRc2YPLv2RQuZmZkmSkZEICLUrVuXrVu3lulzUlOqc9opbUI+mGtEBj538SjkEZxDthNEZCnwOvCBqnparqpyXnkmSkakUF7/FitKlHbvzUAEUiM0K7BRdqjqYmCxiMQCpwFXAy8BnqIGFbWUt5eil/IsLJFhGEHZtGUXsbGxJkylJEpnTLheeX1wZk6dAM8plIJ65alqiqqmFnKleBElN8f7FhH5IUj9AF8kCRH5n4gc55YfISILRWSViPwoIjcF9LlHRNaLyEr3OsfrG40UYmNjSUtLo127dlx88cWkp6cDkJxcfM6Yk046qdg2gXz11VeccMIJpKWl0bp1a+655x5/3XvvvUeHDh1o3bo17du357333vPXDRkyhKSkJPbuPZQJ+eabb0ZE2LbN8/6lUYXZtXs/Yye9xz2PvceuPekVbU5UE40hiUTkDeBnnNnS0zjnmm702t+zu7iINBCRI32Xhy5TgbOKqP8/oJuqtgfuA6a45QeBW1W1DY5Hx/Ui0iag32OqmuZeH3m1P1KoXr06K1eu5IcffiAhIYFnn33Wc9///e9/IT1r8ODBTJkyxf+8Sy65BIBvv/2WkSNHMnv2bH766SfmzJnDyJEj+e677/x9jz76aGbPng1Abm4uCxYs4PDDDw/p+UbVZM++DL754Q++/2Udy3/4g+9++os9+yp3rL4yJRqVCV4EmqvqMDdDRW4onYsVJhHpKyKrcYRkMbAWmFtcP1X9DNhRRP3/VHWn+/IroIlbvlFVl7v3e3FSvFfIJ+LcuXPp3bs3f/vb3+jduzdz5xb7tkPi1FNPZc2aNXnK9u3bR8+ePenUqRPt27f3iwMcmlUtWrSI7t27c9FFF9GqVSsGDBhQaPrlLVu20LhxY8CZqbVp4+j7I488wp133un3BmvWrBmjR4/m4Ycf9ve97LLLmDVrlv95J598MnFxVep0gREi+zMOsGHzLsZOepcbx77qLx9253TufWw2G7fsIj3D8xlLA6LyHJOINABOBmaJyFsicq+INAxlDC8zpvtwZi6/qmozoCeOkISTqyhE7ESkKdAR+Dqg+AZ3CfAlN3VvoYjINW7G3WUl8XyaO3cu48ePZ9OmTagqmzZtYvz48WETp4MHDzJ37lzat2+fpzwxMZF3332X5cuXs3DhQm699dZCRWfFihU8/vjjrFq1it9//50vvviiQJsRI0Zw7LHHcsEFF/Dcc8/5z2/9+OOPHH/88Xnadu7cmR9//NH/+phjjmHr1q3s3LmTmTNnctlll4XjbRuVGAGmv/0F8z//qUDdvP/+yCvvfFn+RlUComnCJCInA0txzJnuXgBfu3We8CJM2aq6HYgRkRhVXQh0DtXgYIhIDxxhGpWvPBl4G7hZVfe4xc8ALYA0YCMwKdi4qjpFVTurauf69euHbNfkyZMLHMTNzMxk8uTJIY8VSEZGBmlpaXTu3JkjjzySq666Kr/d3HnnnXTo0IHTTz+d9evXs3nz5gLjdOnShSZNmhATE0NaWhpr164t0Gbs2LEsW7aMM844g9dee42zzipqZbUg/fr14/XXX+frr7/m1FNPDamvUfVIql6NG4eczsczbuGEtEMZDk46vgUfz7iV6wafRlL1ahVoYZQSTcrkfCafr6p3q+oc97obOB941OsgXtZmdrki8RnwqohsAUI+MFUYItIBeAE42xU/X3k8jii9qqrv+MpVdXNAm+fxGKm2JBQmBkWVe8W3xxSMV199la1bt/LNN98QHx9P06ZNC41UUa3aof/gsbGxHDx4sNDxWrRowbXXXsvVV19N/fr12b59O23atOGbb77huOOO87f75ptvaNu2bZ6+l156KccffzyDBw8mJsaiVxnFUyOpGjWSqvHwvy7hrEGPEhMrTBh9CfVqF+/cYxQkCs8xparqivyFqrpSRFK8DuJFmM7DSQw4AhgA1ATGeX1AMFwHineAQar6a0C54Gyc/aSqj+br01hVN7ovLwAK9fgLBw0bNmTTpk2Flpclu3fvpkGDBsTHx7Nw4UL++KPkx8k+/PBDzjnnHESE1atXExsbS61atRg5ciQXX3wxp512Gk2bNmXt2rU88MADvPXWW3n6H3XUUYwfP57TTz+9tG/LqGKkJCdy7aAeJCTEkZqcWNHmRDVRJkwiIrUD/Ad8hXUIwdmuSGFyD0d9oKo9gFxC8EMXkZlAd6CeiKwD7gbiAVT1WWAsUBf4t3vQ8KCqdsbZNBsEfC8iK93h7nQ98B4SkTScLxJrgX96tSdUrr/+esaPH59ntpKYmMj1119fRK/SM2DAAPr06UP79u3p3LkzrVqVPCfjjBkzGDFiBElJScTFxfHqq6/63dUnTpxInz59yM7OJj4+noceeoi0tLQCY/zzn2X2KzYqMdUS4rngrE6AVOqU7uVBdOkSjwGfishIYLlbdjww0a3zhBS2sZ6ngch8oJ+q7i6hoRVO586dddmyZfz000+0bu09/+HcuXOZPHkymzdvpmHDhlx//fWcffbZZWipUdUI9d9kNHEwJwdBiK2ApIT7M7NIiIslPi623J8NICLfuF+0S0Vi4yP0yME3e26/euLIsDy3NLiZam8H2uLo6irgYVV93+sYXr7K7MOZvcwjYG9JVYeHZm70cfbZZ5sQGUYJiYutGFHYunsfVz/5DhP+cRYtGtWtMHEKF9EWXVxVP6CU+/9evsq8A4zBcX74JuAyDMOIKLbu3kf/h15n+W8b6Hf/K/y2aTvZB3Mq2qySE4pHnkf9EpGzROQXEVkjIncUUn+UiMx3j+UsEpEm+epTRWSdiDxdindWJMUKk6pOA94AvlLVab6rrAwyDMMoCT5R+nW9EzZrX2ZWpRCncB6wdf0GJgNnA22A/vki64ATGXy6m9poHPBgvvr7cCYqZYaXyA99gJU42QgRkTQRmVOWRhmGYYRCflHyUVnEKYx0Adao6u+qmoWTjuK8fG3aAAvc+4WB9SJyPNAQ+LQsjfSylHcPzpvZBY4/OtA8eHPDMIzwkJGZVWybfRkHeHneNwVEyV+fmcXIFz8iKwqFyXeOKYQZUz1fxBv3uibfkIcDfwW8XkfBkG/fAv3c+wuAFBGpKyIxOAdoR5bkvYhIJ69tvUZ+yO+RF1JAPsMwjFDZvTeDPzbt5GBO0R83ydWrcc1ZXTjvhMK9G5s3qsNLN11EjcSEsjAz0tjmi3jjXlOK71KAkUA3EVkBdAPWAznAdcBHqrquhLZd67WhF2H6UUQuB2JFpKWIPAWEFuba8FNV0l4MGTKEZs2akZaWRqdOnfjyy9DipHn5fZQHV155JQ0aNKBdu3Z5ynfs2EGvXr1o2bIlvXr1YufOnUFGMErK+q27GDx2uqfI5LWSq3PfoDMKiFPzRnV4447LaVArMv49lYQwB3FdDxwR8LqJWxbwPN2gqv1UtSPwL7dsF3AiTqzStTj7UFeIyATv70Ov9trWizDdiOOPfgAnh/tu4GavDzDyUtnSXixatIghQ4YU+vyHH36YlStXMmHChEIP6ubkRP7SypAhQ/j4448LlE+YMIGePXuyevVqevbsyYQJnv9/Gh7YvTeDf01+nx2705n16XIyDmQX2ye/OFUGUQLC7ZW3FGgpIs1EJAG4DMjjMyAi9dxlO4DROJlnUdUBqnqkqjbFmVVNV9UCXn3uGCeLSA33fqCIPCoiR3l9y16EqZWq/ktV/+Zed3nN2x7NZGdnc+ONN3LjjTeSnp7uv8/OLv4/iFeqStqLrl27+t9n06ZNGTVqFJ06deLNN99k5syZtG/fnnbt2jFqVJ44vowYMYK2bdvSs2dPiosQv3//fq688kq6dOlCx44d/b+3m266iXHjnAhan3zyCV27diU3N5chQ4YwbNgwOnfuzDHHHMMHHxR+7KJr167UqVOnQPns2bMZPHgw4HwBCJxxGiVnX/oB/ty0gxGT3uaHNU70sSdnLuLpWYvZtmsf2dmFx4T04ROna885odKIUjhnTKp6ELgB+AQnpdAbqvqjiIwTkb5us+7ALyLyK46jw/gSWP4MkO4mgL0V+I1DkcaLxYswTRKRn0TkPhFpV3zzysEtt9zC8uXLWb58Oeecc47//pZbbgnL+FUp7cX777+f533WrVuX5cuX07VrV0aNGsWCBQtYuXIlS5cu9X/A79+/329Tt27duPfee4t8xvjx4znttNNYsmQJCxcu5LbbbmP//v08+OCDzJo1i4ULFzJ8+HBefvllf0DatWvXsmTJEj788EOGDRtGZmYmGzZs4Jxzik+MvHnzZr/oN2rUqNTBfQ04kHWQxctX0+vap/nvit/85Qdzcpny9hf0Hv4sW3bu40BW8eJ0Q5+Tol+UyghV/UhVj1HVFqo63i0bq6pz3Pu3VLWl22aoqhZIoqWqU1X1hiIec1CdD67zgKdVdTLgOYirl3NMPYAewFbgOTcV+l1eHxDtHDhwgH379nHgQHgSnFWWtBe+vauhQ4cyZ84c0tLSSEtL45NPPvG3ue2220hLS2PKlCm8+OKL/vJLL70UgKVLl9K9e3fq169PXFwcAwYM4LPPnOMRMTEx/nYDBw7k888/L9LWTz/9lAkTJpCWlkb37t3JzMzkzz//JCkpieeff55evXpxww030KJFC3+fSy65hJiYGFq2bEnz5s35+eefOeyww/joo9ASI4sIbrxHoxRUS4jjlONa8O6kq2nborG/XATO796B2Y9dQ+3UJKolFD9zT6lE6TWiLVGgy14RGQ0MBD50lwbjvXb2tDajqpuAJ0VkIU4MpLHA/SUwNmqYOHEi55xzTh5B8gU7LQ2VJe3F1187uRsXLVrE1KlTmTp1aoFnP/zww1x00UUFymvUqBH0/QejuA9+VeXtt9/m2GOPLVD3/fffU7duXTZs2FDkmKGIS8OGDdm4cSONGzdm48aNNGjQwHNfIzg1U6pTM6U6L98zkMvvfJk1f21j6Pkncd0lXUlOqjxi453IUxyPXApcDlylqpvcbBIPF9PHj5cDtq1F5B4R+QHweeQ1KaZb1DNq1KgC+0nZ2dncfvvtZfrccKe98C0D5k978eCDD/pnWb60F7feemue/r60F9ddd12JbSiKLl26sHjxYrZt20ZOTg4zZ86kW7dugONw4UvD8dprr3HKKacA8PTTT/P00wUjoZx55pk89dRT/ve7YoWTEuaPP/5g0qRJrFixgrlz5/oFFeDNN98kNzeX3377jd9//71QUQtG3759mTbNCYAybdo0zjsv/xlFozTUTk3i/uv6kFKjGleef2IVFSWHMEckKi8uB2ap6n8BVPVPVQ3rHtNLwE7gDFXtrqrPqOqWktkafVSrVo3k5OQ8M5SyZMCAASxbtoz27dszffr0Uqe9OPbYY0lLS2PQoEGFpr1o1aoVffr0KTLtReDyVzhp3LgxEyZMoEePHhx33HEcf/zx/g/4GjVqsGTJEtq1a8eCBQsYO3YsAD///DN169YtMNaYMWPIzs6mQ4cOtG3bljFjxqCqXHXVVTzyyCMcdthhvPjiiwwdOtQ/Az3yyCPp0qULZ599Ns8++yyJiYkF9pj69+/PiSeeyC+//EKTJk38S5J33HEH8+bNo2XLlvznP//hjjsKdU4ySkGLI+rx3L/6U7NGFc/nFJ3KlIKT/uK/InKDiISUyM5L2ovqOOnMwQllEXUeeSVJe5Gdne13dJg4caLfY+zRRx8lPt7zUqkRZnr37s0777xDQkLpDksOGTKE3r17F7rUWJ5U5rQX4SA9M4ukKDwYG660F9UaNtFGl97kuf2fT91e4WkvAnGzlF8KXAisU1VPWUeD7jGJSBzwAPAP4E9AgCNE5GXgX6oaPr/pCCQ+Pp6nnnrK/zrw3qg4grl1G5WTaBQlIw9bgE3AdsDzRmxRzg8P40zHmqvqXnDCneOc+H0E8C7jhhFhFOasYRiRRgR623lCRK4DLgHqA28CV6vqKq/9ixKm3sAxGrDWp6p7RORa4GdMmAzDMIzCOQK42Q36HTJFCZNqIRtQqpojIlGo4YZhGFFIFH7aquro0vQvyitvlYhckb9QRAbizJgMwzCMsiY6vfJKRVHCdD1wvZtad5J7LQaG4zF8uYi8JCJb3DNQhdUPcNP3fi8i/3PjKvnqCk3/6wYf/Notn+UGIjQMw6iUqKrnq7IQVJhUdb2qnoCTWnete41T1S6quj5Yv3xMBYqKg/N/QDdVbY+TrncKFJv+dyLwmKoejXO+6qoCo0YwlvbCG5GQ9uKvv/6iR48etGnThrZt2/LEE0/46yzthVFuROGMSURq+CKUi8gxItJXRDyfs/ESK2+Bqj7lXvNDMU5VPwN2FFH/P1X1/Y/+ikMRJQpN/ytOzJjTgLfcdtOA80OxqaKxtBeHiPS0F3FxcUyaNIlVq1bx1VdfMXnyZFatchyLLO2FYRTJZ0CiiByOk4Z9EM5ExRNeIj+UF1cBc937YOl/6wK73NDtgeUFEJFrfOmFi0uZUFFY2ovITnvRuHFjOnVyskGnpKTQunVr1q93Fgss7UXkczAnh+370tmTEXUxAQ4RymwpgmZMOMEb0nFStP9bVS/GyevniYgQJhHpgSNMo4pr6xVVneJLL1y/fv0SjdG1a1c6d+7sv7p27Rou8yztRZSlvVi7di0rVqzghBNOACztRaRzMCeHP7bv4pzHXuLVr1ZWHXGKHERETgQGAB+6ZbFeO1e4MLkhK14AzlPV7W5xsPS/24FablSKwPIywbf/E+x1SbC0F9GX9mLfvn1ceOGFPP7446SmphZ4tqW9iCx8onT5czPZk3mAJ//zRfSLU/RxE07223fdRITNgYVeO5dsbSZMuKHQ3wEGqeqvAVX+9L84wnMZcLmqqpt64yKcfafBwGyiCEt7EV1pL7Kzs7nwwgsZMGAA/fr185db2ovIJL8o+XjyP86KwoC/p5FaPcqCwkbWTKhYXOe1vqrqy4iLqv6O49HtiTKdMYnITOBL4FgRWSciV4nIMBEZ5jYZi7Nv9G8RWSkiyyB4+l+3zyjgFhFZ4/Z9kUqEpb2InLQXvujkrVu3LpC52NJeRB7BRMlH1M6coixToKrmAKeUZowynTGpav9i6ocCQ4PUfQQUSCXqKm+XsBhYDElJSXmW75KSksr8mQMGDKBPnz60b9+ezp07lzrtxYgRI0hKSiIuLq7QtBfZ2dn+BIjB0l6UFYFpL1SVc889t0Dai/vvv58GDRr4HTF+/vlnTj755AJjjRkzhptvvpkOHTqQm5tLs2bNeP/99wukvRgyZAhLly4FDqW92LNnT560F0OHDuWjjz7iiy++YMaMGbRv397/u3nggQc455xzuOOOO7jkkkt48cUXOeqoo3jjjTfK7PdkeCMrJ4eNu/awPysraJtVGzZHyud3ZWeFiMzBiZO331eoqu946Vxs2ovKQEnSXhiRiaW9MIoiIyuLJf+3jutfeY+c3Lyfbae3OZr7LjiDWknVy9yOcKW9SKjfRBued6Pn9utevCMi0l64WSjyo6p6pZf+FbrHZBihYmkvjKKonpBAl2ZNmDzw/DziVJ6iFG6i0a1GVf9Rmv4V7pVnGBXB1KlTK3y2ZJQNgeIUGyNRLUookBvCFSGISBMRedcNSbdFRN4WkSbF93SwGZNhGJUOnzjN/OflHFGnZnSKkp+o3G55GXgNuNh9PdAt6+Wls82YDMOolFRPSKDtYQ2jXJSI1gO29VX1ZVU96F5TcZIGesKEyTCMSktMTDTu0OQjOoVpu4gMFJFY9xqIEyDBEyZMhmEYRri5Eie1+ib3ugjw7BBhwlTOBKa96NOnD7t27Sqy/cqVK/OEyJkzZ07YIllXZFoMwzCKRwBR71ekoKp/qGpfVa3vXuer6p9e+5swlTOBaS/q1KnD5MmTi2yfX5j69u3LHXfcUUQP75RHWgzDMEqBEnWRHwBEpLmIvC8iW12vvNluvDxPmDAVgy/CeDgji/s48cQT/WkUlixZwoknnkjHjh056aST+OWXX8jKymLs2LHMmjWLtLQ0Zs2axdSpU7nhhhsAZ+YyfPhwTjrpJJo3b+4P4ZObm8t1111Hq1at6NWrF+ecc46/LpBISYthGEal4zXgDaAxcBhOBIiZXjubMBWDLyRROCKLB5KTk8P8+fPp29eJc9iqVSv++9//smLFCsaNG8edd95JQkIC48aN49JLL2XlypX+aNuBbNy4kc8//5wPPvjAP5N65513WLt2LatWrWLGjBlBs8dGSloMwzCKIDqdH5JUdUaAV94rgOfoufYVNwhdu3YlPT2d2NhYcnJyiI2NpXPnziQlJflTM5QEX9qL9evX07p1a3r1ctz6d+/ezeDBg1m9ejUiQnZ2tqfxzj//fGJiYmjTpo0/Pcbnn3/OxRdfTExMDI0aNaJHjx6F9h07diwDBgzg008/5bXXXmPmzJksWrTI83sJTIvx3HPPee5nGEYIRJbgFImI1HFv54rIHThZIBS4lEJinwbDZkxB8M2QfOm/fT9LO3Py7TH98ccfqKp/j2nMmDH06NGDH374gffff7/QVBeFEZj+oiRxD31pMebPn8+3336bJy1GIMHSYowZM4ZevXoVSIthGEZ4kBCuCOAbYBmOR94/cXIwLQKuxREnT9inSRB8kcRjY2Pz/AxXhPGkpCSefPJJJk2axMGDB9m9e7ffeSAwt1FKSkoe7zcvnHzyybz99tvk5uayefPmoLOgSE+LYRiGQm4IV0Vbq9pMVZu7P/Nfnp0fbCkvCL7lus6dnUC9OTk5LFu2LKzP6NixIx06dGDmzJncfvvtDB48mPvvv59zzz3X36ZHjx7+zKyjR4/2NO6FF17I/PnzadOmDUcccQSdOnWiZs2aBdpFeloMwzCiFxE5CWhKgM6o6nRPfS3tRdH49ppKu7dU3uzbt4/k5GS2b99Oly5d+OKLL2jUqFFFm2Xkw9JeVE7ClfaiWp3D9bAzr/fcfu3r/4qUtBczgBbASiDHLVZV9ZTF1mZMxRBNYhRI79692bVrF1lZWYwZM8ZEyTCileicPHQG2mgJZz4mTJWUULzrDMMwwswPQCNgY0k6mzAZhmFEMlE0YRKR93EsTgFWicgS4ICvXlX7ehnHhMkwDCOCiaQYeB54JByDlJkwichLQG9gi6q2K6S+FU7iqE7Av1T1Ebf8WGBWQNPmwFhVfVxE7gGuBra6dXeqqudDW4ZhGNFH9CiTqi4OxzhlOWOaCjwNBHMP3AEMB84PLFTVX4A0ABGJBdYD7wY0ecwnYoZhGJWe6NElPyKyl4KW78Y5fHurqv5eVP8yO2Crqp/hiE+w+i2quhQoKvZOT+A3Vf0j3PZVFJb24tAYzZo1Iy0tjU6dOgWN5xeM5OTkkNqXFVdeeSUNGjSgXbu8iwI7duygV69etGzZkl69erFz584KstCIakJIeeF1yU9EzhKRX0RkjRs2KH/9USIyX0S+E5FFItLELU8TkS9F5Ee3rqhIDo8DtwGHA02AkTiBXV8HXirOxkiP/HAZBSPS3uD+Ul4SkdrBOorINSKyTESWbd26NVizcqeqpb1YtGgRQ4YMKfT5Dz/8MCtXrmTChAmFHtT1hYGKZIYMGcLHH39coHzChAn07NmT1atX07Nnz7B9mTCqIGEM4uquQk0GzgbaAP1FpE2+Zo8A01W1AzAOeNAtTweuUNW2wFnA4yJSK8ij+qrqc6q6V1X3qOoU4ExVnQUE/dz2EbHCJCIJQF+ccOk+nsE5tJWG44Y4KVh/VZ2iqp1VtXP9+p5TzRdg2bJl9OrVK+xRH8DSXvjo2rUra9asAaBp06aMGjWKTp068eabbzJz5kzat29Pu3btGDVqVJ5+I0aMoG3btvTs2ZPivnzs37+fK6+8ki5dutCxY0e/qN50002MGzcOgE8++YSuXbuSm5vLkCFDGDZsGJ07d+aYY47hgw8+CGp7nTp1CpTPnj2bwYMHA84XgMAZp2GERljDi3cB1qjq76qahTODOS9fmzbAAvd+oa9eVX9V1dXu/QZgCxDswzVdRC4RkRj3ugTwBQAt1tCIFSYcRV+uqpt9Baq6WVVzVDUXeB7nl1xmLFu2jJtvvpmdO3dy8803h1WcLO3FId5//33at2/vf123bl2WL19O165dGTVqFAsWLGDlypUsXbrU/wG/f/9+v03dunXj3nvvLfIZ48eP57TTTmPJkiUsXLiQ2267jf379/Pggw8ya9YsFi5cyPDhw3n55Zf9AWnXrl3LkiVL+PDDDxk2bBiZmZls2LCBc845p9j3tHnzZr/oN2rUyB/53TBCQQDJ9X4B9XwrRe51Tb4hDwf+Cni9zi0L5Fugn3t/AZAiInXz2CXSBUgAfgti+gBgEI54bXbvB4pIdeCG4t53JAtTf/It44lI44CXF+Ac4ioTfKLk+7DOzMwMizj50l74PqwC015cfPHFtGvXjhEjRuQRgaIobdqLZcuWccYZZ/Daa69x1llnhfReAtNenHrqqXnqfHtXQ4cOZc6cOaSlpZGWlsYnn3zib3PbbbeRlpbGlClTePHFF/3lPgFeunQp3bt3p379+sTFxTFgwAB/JI6YmBh/u4EDB/L5558Xaeunn37qjznYvXt3MjMz+fPPP0lKSuL555+nV69e3HDDDbRo0cLf55JLLiEmJoaWLVvSvHlzfv75Zw477LA8S6teEBFEIiT2sxGFhDRj2uZbKXKvKSV44Eigm4isALrhOKD519Xdz+EZwD/cSUJBi50ZWR9VreemVu+jqmtUNUNVi/7PStm6i88EuuMo+DrgbiDeNfpZEWmE46GRCuSKyM04ISz2iEgNoBdO2PRAHhKRNJy/wNpC6sPG6NGjC6SeyMzMZPTo0cybN6/E4/r2mNLT0znzzDOZPHkyw4cP96e9ePfdd1m7di3du3f3NF640l5cffXV1K9fP0/ai+OOO87fLljai+OPP57BgwcXSHvx9ddfA84y39SpU/NETPfx8MMPc9FFFxUor1GjRsjvo7gPflXl7bff5thjjy1Q9/3331O3bl02bNhQ5JihiEvDhg3ZuHEjjRs3ZuPGjTRo0MBzX8PwE/4EgOuBIwJeN3HLDj3SWabrByAiycCFqrrLfZ0KfIhzxOer/IOLyO2q+pCIPFWY5V5j5ZWlV15/VW2sqvGq2kRVX1TVZ1X1Wbd+k1ueqqq13Ps9bt1+Va2rqrvzjTlIVduragdV7auqJQp34YUHH3yQxMS8CRcTExN58MEHg/QIDUt7UTxdunRh8eLFbNu2jZycHGbOnEm3bt0AZx/Nt2/22muvccoppwDw9NNP8/TTTxcY68wzz+Spp57yv98VK1YA8McffzBp0iRWrFjB3Llz/YIK8Oabb5Kbm8tvv/3G77//XqioBaNv375MmzYNgGnTpnHeefmX8Q3DG2H2ylsKtBSRZu4+/mXAnDzPE6knIj5tGI3rRee2fxfHMaLgprXDT+7PZTi5mfJfnojkpbwKpXPnzjz++ON+cUpMTOTxxx/3p8EIB/nTXowePZqOHTty8OBBf5sePXqwatUqv/ODFy688EKaNGlCmzZtGDhwYJFpL4499ljS0tIYNGhQoWkvWrVqRZ8+fYpMexG4/BVOGjduzIQJE+jRowfHHXccxx9/vP8DvkaNGixZsoR27dqxYMECxo4dC8DPP/9M3bp1C4w1ZswYsrOz6dChA23btmXMmDGoKldddRWPPPIIhx12GC+++CJDhw71z5SPPPJIunTpwtlnn82zzz5LYmJigT2m/v37c+KJJ/LLL7/QpEkT/5LkHXfcwbx582jZsiX/+c9/wuZJaVQ1QlnGK16ZVPUgzh7PJzgi8oaq/igi40TEFy6oO/CLiPwKNATGu+WXAF2BISKy0r3S8o3/vvtzmqpOA9703buvPWFpL4ph2bJljB49mgcffDCsolTWVNW0F7179+add94hISGhVOMMGTKE3r17F7rUGE4s7UXlJFxpLxJrHaZHdPW+Y7Hm/XsiJe3FicCLQLKqHikixwH/VFVPyysWK68YOnfuXKo9pYqiqqa9CObWbRjRSpTFyvPxOHAm7jKhqn4rIl29djZhqqRY2ovSUZizhmFUDNGpTKr6Vz6HIc8n5k2YDMMwIpno1KW/3NTqKiLxwE0ccowoFnN+MAzDiFTC6/tQngwDrsc5vLseJ1qP5xzxNmMyDMOIYCQKHdRUdRtO9IcSYcJkGIYRyUSRLonI2CKqVVXv8zKOLeWVM5b24tAY0Z724q+//qJHjx60adOGtm3b8sQTT/jrLO2FES5E1fMVAewv5AK4ChgVrFN+TJjKGUt7cYhoT3sRFxfHpEmTWLVqFV999RWTJ09m1apVgKW9MKomqjrJdwFTgOrAP3CimDf3Oo4JUzFs3ryZvn37lkl0aEt74RCtaS8aN25Mp06dACd0VOvWrf1/T0t7YYQNVe9XBCAidUTkfuA7nO2iTqo6SlW3eB3DhKkYHn/8cTZt2pRnmSYcWNqLQ1SGtBdr165lxYoVnHDCCYClvTDCRJR55YnIwzjx+PYC7VX1HlUNeR3bhCkImzdvZvTo0SxevJjc3FwWLVrE6NGjS/0BY2kvKl/ai3379nHhhRfy+OOPk5qaWuDZlvbCKCkS4hUB3AocBtwFbBCRPe61V0T2eB3EvPKCcPXVV7Np0yZyc510I1lZWcyfP58ff/yROXPmFNM7OJb24hCVIe1FdnY2F154IQMGDKBfv37+ckt7YYSHyFmi84KqhmWyYzOmIDz//POcfvrp/mCgCQkJnH766Tz//PNhGd/SXhRPpKe98EUnb926NbfcckueOkt7YYSNKFrKCxcmTEFo2LAhDzzwAN26dSMmJobu3bvzwAMP0LBhw7A9w9JeFE2kp7344osvmDFjBgsWLPAvVfqW+SzthRE2osz5IRxY2oti2Lx5M1dffTXPP/98WEWprLG0F5b2wqg4wpX2onpqY232tys9t/9pwQMRkfaitNgeUzE0bNiwVHtKFYWlvTCMSkLlnzsUwISpkmJpL0qHpb0wIgKlUi3RecWEyTAMI4KJkFBD5UqZOT+IyEsiskVEfghS30pEvhSRAyIyMl/dWhH53s0pvyygvI6IzBOR1e7P2mVlv2EYRkRgXnlhZSpQ1InNHcBw4JEg9T1UNS3fRt4dwHxVbQnMd18bhmFUXkyYwoeqfoYjPsHqt6jqUiA7hGHPA6a599OA80tsoGEYRjGoKrm5FR1MuOopU6TuMSnwqYgo8JyqTnHLG6rqRvd+ExDUf1tErgGuAec8SiSwfft2evbsCcCmTZuIjY2lfv36gBPEtSQuzsnJyezbty+sdhqG4XDgYAa/bf+RY+ofR3xs6Y4glJjKozeeiVRhOkVV14tIA2CeiPzszsD8qKq6wlUorphNAeccU9ma6426deuycuVKAO655x6Sk5MZOXJk0Z0Mw6gQVJVt+zfy3YYvaVanVcUIUyU7OOuViIz8oKrr3Z9bgHeBLm7VZhFpDOD+9BxGvaRs27aN8847z3MCvFCZP38+HTt2pH379lx55ZUcOHAAcNI/3H777bRv354uXbr400IUZeeJJ57Ihx9+WCZ2GkZV48DBDJav/y+K8v3Gr8nOyaoQO6IsiGtYiDhhEpEaIpLiuwfOAHyefXOAwe79YGB2WdvzwgsvsGHDBl544YWwj52ZmcmQIUOYNWsW33//PQcPHuSZZ57x19esWZPvv/+eG264gZtvvjnoOJs3b+bcc89l3LhxnHvuuWG30zCqGr7Z0r4DuwH4ffsqsnMOVJAxIVyVhLJ0F58JfAkcKyLrROQqERkmIsPc+kYisg64BbjLbZOKs2/0uYh8CywBPlTVj91hJwC9RGQ1cLr7uszYtm0b77//PqrK+++/H/ZZU05ODs2aNeOYY44BnIRyvrQOAP379/f/DJZTKTs7m549e/LQQw/5U2gYhlE6fLMlHxU6a6qCsfLKbI9JVfsXU78JaFJI1R7guELKUdXtQM/SW+eNF154wZ/2Ijc3lxdeeKFcg3EGplkQEXJycvwJ/Pr27cu4ceOIi4vj+OOP55NPPvFH3jYMo+Tkny35+H37Kto3PqH895oqj954JuKW8iIF32wpO9vxZs/Ozg77rCk2Npa1a9f6949mzJiRR1x80cRnzZrFiSeeSGxsLCtXrmTlypX+dOAiwksvvcTPP//MxIkTw2abYVRV8s+WfCjKdxW411SVMGEKQuBsyYdv1hQuEhMTefnll7n44otp3749MTExDBs2zF+/c+dOOnTowBNPPMFjjz0WdJzY2FhmzpzJggUL+Pe//x02+wyjqhFstuTj/8p7r0mBXPV+VRIi1V28wlm8eLF/tuQjOzubxYsXh2U575577vHf+5LW5ee2224rdhbkO8NUrVq1PGnLDcMInaycTDbvW8/hNZsFbbNp718cUevoclvSC34opvJiwhSEuXPnVrQJhmGUM7Ex8XRo/Pdi28VIbDlY46PqKZMJU4TiS2tuGEb5ERcTgR+JVU+Xqp4wqWoebzfDqCiqQvZoIwxUwX8mVcr5ITExke3bt9sHglHhqCrbt28nMTGxok0xIh07x1S5adKkCevWrWPr1q0VbYphkJiYSJMmhR3lMwyXShbRwStVSpji4+Np1iy4t41hGIZR8UhVWNYSka3AH+X4yHpA2UR9LT1mW8kw20pGVbXtKFWtX9pBRORjHDu9sk1Vi0rQGhVUCWEqb0RkWb7MuxGD2VYyzLaSYbYZJaFKOT8YhmEYkY8Jk2EYhhFRmDCVDVOKb1JhmG0lw2wrGWabETK2x2QYhmFEFDZjMgzDMCIKEybDMAwjojBhKiEicpaI/CIia0SkQB4MEblFRFaJyHciMl9Ejoow+4aJyPcislJEPheRNpFiW0C7C0VERaTcXHo9/N6GiMhW9/e2UkSGRoptbptL3H93P4rIa5Fim4g8FvA7+1VEdkWQbUeKyEIRWeH+fz2nvGwzgqCqdoV4AbHAb0BzIAH4FmiTr00PIMm9vxaYFWH2pQbc9wU+jhTb3HYpwGfAV0DnSLENGAI8HaH/5loCK4Da7usGkWJbvvY3Ai9Fim04ThDXuvdtgLXl/fe1K+9lM6aS0QVYo6q/q2oW8DpwXmADVV2oqunuy6+A8gyK5sW+PQEva1B+EbmKtc3lPmAikFlOdoViW0XgxbargcmquhNAVbdEkG2B9Admlotl3mxTINW9rwlsKCfbjCCYMJWMw4G/Al6vc8uCcRVQnpkHPdknIteLyG/AQ8DwSLFNRDoBR6jqh+Vkkw+vf9cL3SWft0TkiPIxzZNtxwDHiMgXIvKViJRXaBrP/x/cJe1mwIJysAu82XYPMFBE1gEf4czojArEhKmMEZGBQGfg4Yq2JT+qOllVWwCjgLsq2h4AEYkBHgVurWhbgvA+0FRVOwDzgGkVbE8gcTjLed1xZiXPi0itijSoEC4D3lLVnIo2JID+wFRVbQKcA8xw/x0aFYT98kvGeiDwm3ITtywPInI68C+gr6oeKCfbwKN9AbwOnF+WBgVQnG0pQDtgkYisBf4OzCknB4hif2+quj3gb/kCcHw52OXJNpzZwBxVzVbV/wN+xRGqSLDNx2WU3zIeeLPtKuANAFX9EkgktMCpRrip6E2uaLxwvpn+jrMk4dtQbZuvTUecTdeWEWpfy4D7PsCySLEtX/tFlJ/zg5ffW+OA+wuAryLItrOAae59PZwlrLqRYJvbrhWwFvdgfwT93uYCQ9z71jh7TOVmo10FryqVjylcqOpBEbkB+ATH6+clVf1RRMbhfMDPwVm6SwbedFO5/6mqfSPIvhvcGV02sBMYHEG2VQgebRsuIn2Bg8AOHC+9SLHtE+AMEVkF5AC3qer2CLENnNnS6+oqQHng0bZbcZY9R+A4QgwpTxuNglhIIsMwDCOisD0mwzAMI6IwYTIMwzAiChMmwzAMI6IwYTIMwzAiChMmwzAMI6IwYTIKICJNRGS2iKwWkd9E5AkRSfDYd1Goh2FFZJzrul5uiMhaEYmKQ5Ru6KPmxbS5R0TWu9G7V4vIO4ER40UkXkQmuHXLReRLETnbrUsWkWfcv/VyEflGRK526+qLyMdl+w4NIy8mTEYexDl09Q7wnqq2xIm/lgyML6Rtqc/BiUisqo5V1f+UdqzCxg73mOWNiLQFYlX1dw/NH1PVNPfvNgtYICL13br7gMZAO1XthBPpI8WtewHnLFtLt+4soA6Aqm4FNorIyeF6T4ZRHCZMRn5OAzJV9WUAdWKajQCuFJEkNx/RHBFZAMwXkeoi8rqI/CQi7wLVfQOJyBnuN/PlIvKmiCS75WtFZKKILAcuFpGpInJRQN29bp/vRaSVW15fROa5eYZeEJE/CpvxiMg+EZkkIt8CJ4rIQBFZ4s4knitMrAprI06+qocD2gwRkafd+/fcWcWPInJNvmePF5FvxQmi2tAtbygi77rl34rIScGeW8jfYwAwu7hn5EdVZwGfApeLSBJO5PEb1Q2npKqbVfUNEWmBE4H7LlXNdeu2qurEgOHec+0wjHLBhMnIT1vgm8ACdVJk/Akc7RZ1Ai5S1W44uabSVbU1cDdu7DhXNO4CTne/hS8DbgkYdruqdlLV1wuxYZvb5xlgpFt2N7BAVdsCbwFHBrG/BvC1qh4HbAcuBU5W1TScaAh5PmBFpHWQNm/jhBzycSlOTEGAK1X1eJzgvMNFpG7As79yn/0ZjhgAPAksdss7AT8W8dz8nEzev0ewZxTGcpwwQEfjRB7ZU0ibtsC3PlEKwjLg1CLqDSOsWEgioyTMU9Ud7n1XnA9eVPU7EfnOLf87TtK1L5zVQRKALwPGmFXE+O+4P78B+rn3p+AKhap+LCI7g/TNwREVgJ44QrnUtaE6kD9HUaFtVHWriPwuIn8HVuN8wH/h9hkuIj7ROgInUOp2IAv4IMD2Xu79acAVru05wG4RGeTBNnCW37YGvA72jMKQIuoK7yDyL+BinCSDh7nFW4DDgvcyjPBiwmTkZxVwUWCBiKTizFDW4Hzj3+9hHMERsP5B6osawxe9O4fQ/41m6qGUCoIT1HR0Ee2LavM6cAnwM/CuqqqIdAdOB05U1XQRWYQTjRogOyDGWnG2e7ENICNg/FCf0RFntrMGOFJEUguZNa0CjhORGFXNVdXxwHgR2RfQJtG1wzDKBVvKM/IzH0gSkSvA70AwCSdfTXoh7T8DLnfbtgM6uOVfASeLyNFuXQ0ROaYUdn2BIxKIyBlAbY/v5SIRaeD2qyNOojqvbd7FyXban0PLeDWBna4otcKZGXqx41p3/FgRqenRNoCfOLSE6hkRuRA4A5jp/t1eBJ4Q17vS3bO7WFXX4IjX/b49LhFJJO9s6xjgh1BtMIySYsJk5MH9Nn4BjlPCapycPpnAnUG6PAMki8hPwDjc/RDXm2sIMNNd3vsSZzmspNyLEzn7B5ylpk3A3mLeyyqcfa5PXRvm4SyNeWqjToryn4CjVHWJ2+VjIM59vxNwBLg4bgJ6iMj3OL+fNl5sc/kQJ/GfF0a4jhSrgYHAae7fAfdZW4FV7u/wA8A3exoK1AXWiMgy15bbA8bt4dphGOWCRRc3ogIRqQbkuGkMTgSecZ0GKjUiUh1YiOMkUSFZX0XkM+A8V6gNo8yxPSYjWjgSeEOclNdZFO2NVmlQ1QwRuRs4HMczslwR5xzUoyZKRnliMybDMAwjorA9JsMwDCOiMGEyDMMwIgoTJsMwDCOiMGEyDMMwIgoTJsMwDCOi+H+ddtylJ6IUbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ax = sns.scatterplot(x=meanResReducedMerged.nDCG.values, y=meanResReducedMerged.meanOverallDiversity.values, \n",
    "                hue=meanResReducedMerged.neighborOverallRatio.values, \n",
    "                style = zip(meanResReducedMerged.index.get_level_values(1),meanResReducedMerged.index.get_level_values(3),meanResReducedMerged.index.get_level_values(2)),\n",
    "                palette='crest_r',s=100)\n",
    "\n",
    "norm = plt.Normalize(meanResReducedMerged.neighborOverallRatio.min(), meanResReducedMerged.neighborOverallRatio.max())\n",
    "#meanRes.neighborOverallRatio.min(), meanRes.neighborOverallRatio.max()\n",
    "sm = plt.cm.ScalarMappable(cmap=\"crest_r\", norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labelsDict = {\n",
    "   \"('rating', 10, False)\": \"Rating SOM\", \n",
    "    \"('rating', 5, True)\": \"Rating SOM+Prob, exp:5\", \n",
    "    \"('rating', 10, True)\": \"Rating SOM+Prob, exp:10\", \n",
    "    \"('rating', 20, True)\": \"Rating SOM+Prob, exp:20\", \n",
    "    \"('normal', 10, False)\": \"Plain SOM\", \n",
    "    \"('normal', 5, True)\": \"Plain SOM+Prob, exp:5\", \n",
    "    \"('normal', 10, True)\": \"Plain SOM+Prob, exp:10\", \n",
    "    \"('normal', 20, True)\": \"Plain SOM+Prob, exp:20\", \n",
    "    \n",
    "    \"('topk', 10, False)\": \"Top-k\"     \n",
    "}\n",
    "lbls = [labelsDict.get(i,i) for i in labels[-7:]]\n",
    "ax.legend(handles=handles[-7:], labels=lbls, bbox_to_anchor=(-0.01,-0.015), loc=3)\n",
    "ax.set_xlabel(\"Ordering relevance (nDCG)\")\n",
    "ax.set_ylabel(\"Overall Diversity\")\n",
    "\n",
    "ax.figure.colorbar(sm, label=\"Neighbors vs. Overall Diversity Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"VBS_mergedTriangle.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
